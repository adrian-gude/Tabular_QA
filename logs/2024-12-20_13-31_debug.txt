Model:Qwen/Qwen2.5-Coder-32B-Instruct
Accuracy:0.84375
----------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    most_favorited_author = df.loc[df['favorites'].idxmax()]['author_name']
    author_lang = df[df['author_name'] == most_favorited_author]['lang'].mode()[0]
    return author_lang == 'es'
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    most_favorited_author = df.loc[df['favorites'].idxmax()]['author_name']
    author_lang = df[df['author_name'] == most_favorited_author]['lang'].mode()[0]
    return author_lang == 'es'
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    longest_name_author = df.loc[df['author_name'].str.len().idxmax(), 'author_name']
    author_content_type = df[df['author_name'] == longest_name_author]['type'].value_counts()
    return author_content_type.get('original', 0) > author_content_type.get('reply', 0)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    longest_name_author = df.loc[df['author_name'].str.len().idxmax(), 'author_name']
    author_content_type = df[df['author_name'] == longest_name_author]['type'].value_counts()
    return author_content_type.get('original', 0) > author_content_type.get('reply', 0)
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['retweets'].min() == 0
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['retweets'].min() == 0
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return (df['links'].isna() | (df['links'] == '')).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return (df['links'].isna() | (df['links'] == '')).any()
```
Response: __CODE_ERROR__: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search'] # Retain original column names 
    return df['author_id'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    return df['author_id'].nunique()
```
Response: 3943
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    # The columns used in the solution : ['text']
    max_length = df['text'].apply(lambda x: len(x.split())).max()
    return max_length
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    max_length = df['text'].apply(lambda x: len(x.split())).max()
    return max_length
```
Response: 61
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search'] # Retain original column names 
    # The columns used in the solution : ['retweets']
    # The unique values of the columns used in the solution : 
    return df['retweets'].sum()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search'] # Retain original column names 
    return df['retweets'].sum()
```
Response: 1243
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return (df['mention_ids'].isna() | (df['mention_ids'] == '')).sum()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return (df['mention_ids'].isna() | (df['mention_ids'] == '')).sum()
```
Response: __CODE_ERROR__: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    author_with_most_retweets = df.loc[df['retweets'].idxmax()]['author_name']
    return author_with_most_retweets
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    author_with_most_retweets = df.loc[df['retweets'].idxmax()]['author_name']
    return author_with_most_retweets
```
Response: Lavincompae
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    max_favorites = df['favorites'].max()
    return df.loc[df['favorites'] == max_favorites, 'lang'].iloc[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    max_favorites = df['favorites'].max()
    return df.loc[df['favorites'] == max_favorites, 'lang'].iloc[0]
```
Response: es
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    max_words_author = df.loc[df['word_count'].idxmax(), 'author_name']
    return max_words_author
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    max_words_author = df.loc[df['word_count'].idxmax(), 'author_name']
    return max_words_author
```
Response: juan prin
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['type'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['type'].mode()[0]
```
Response: reply
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    top_authors = df.sort_values(by='retweets', ascending=False).head(3)['author_name'].tolist()
    return top_authors
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    top_authors = df.sort_values(by='retweets', ascending=False).head(3)['author_name'].tolist()
    return top_authors
```
Response: ['Lavincompae', '#NI UNA MENOS \xa0♐\xa0✊\xa0🚺', 'SFC The World']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df.sort_values(by='favorites').head(5)['lang'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df.sort_values(by='favorites').head(5)['lang'].tolist()
```
Response: ['es', 'es', 'es', 'es', 'es']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    shortest_posts = df.sort_values(by='word_count').head(4)
    return shortest_posts['author_name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    shortest_posts = df.sort_values(by='word_count').head(4)
    return shortest_posts['author_name'].tolist()
```
Response: ['Jesús Martos Gómez ن', 'meg', 'Jos', 'Marcos A. Infantes']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['type'].value_counts().head(6).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    return df['type'].value_counts().head(6).index.tolist()
```
Response: ['reply', 'original']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search'] # Retain original column names 
    top_5_favorited = df.sort_values(by='favorites', ascending=False).head(5)
    return top_5_favorited['retweets'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    top_5_favorited = df.sort_values(by='favorites', ascending=False).head(5)
    return top_5_favorited['retweets'].tolist()
```
Response: [0, 0, 0, 0, 3]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    longest_posts = df.sort_values(by='word_count', ascending=False).head(3)
    return longest_posts['word_count'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    longest_posts = df.sort_values(by='word_count', ascending=False).head(3)
    return longest_posts['word_count'].tolist()
```
Response: [61, 60, 59]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search'] # Retain original column names 
    # The columns used in the solution : ['favorites','retweets']
    # The unique values of the columns used in the solution : 
    return df.sort_values(by='favorites').head(4)['retweets'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    return df.sort_values(by='favorites').head(4)['retweets'].tolist()
```
Response: [0, 0, 0, 0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    shortest_posts = df.nsmallest(6, 'word_count')
    return shortest_posts['word_count'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'type', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'rp_user_id', 'rp_user_name', 'location', 'tweet_link','search']
    df['word_count'] = df['text'].apply(lambda x: len(x.split()))
    shortest_posts = df.nsmallest(6, 'word_count')
    return shortest_posts['word_count'].tolist()
```
Response: [1, 1, 1, 1, 1, 1]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return 'Pikachu' in df['name'].values
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return 'Pikachu' in df['name'].values
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return (df['total'] > 700).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return (df['total'] > 700).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df[df['generation'] == 1]['legendary'].all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df[df['generation'] == 1]['legendary'].all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['speed'].max() > 150
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['speed'].max() > 150
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['type1'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['type1'].nunique()
```
Response: 20
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['total'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['total'].max()
```
Response: 1125
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return len(df[df['generation'] == 3])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return len(df[df['generation'] == 3])
```
Response: 160
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['attack'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df['attack'].mean()
```
Response: 80.93843283582089
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    max_defense_pokemon = df.loc[df['defense'].idxmax()]
    return max_defense_pokemon['type1']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    max_defense_pokemon = df.loc[df['defense'].idxmax()]
    return max_defense_pokemon['type1']
```
Response: Poison
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.loc[df['speed'].idxmin(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.loc[df['speed'].idxmin(), 'name']
```
Response: Shuckle
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df[df['legendary'] == True]['type1'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df[df['legendary'] == True]['type1'].mode()[0]
```
Response: Psychic
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.loc[df['sp_attack'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.loc[df['sp_attack'].idxmax(), 'name']
```
Response: Mega Mewtwo Y
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    top_3_pokemon = df.sort_values(by='total', ascending=False).head(3)['name'].tolist()
    return top_3_pokemon
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    top_3_pokemon = df.sort_values(by='total', ascending=False).head(3)['name'].tolist()
    return top_3_pokemon
```
Response: ['Eternamax Eternatus', 'Mega Mewtwo X', 'Mega Rayquaza']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.sort_values(by='hp').head(5)['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    return df.sort_values(by='hp').head(5)['name'].tolist()
```
Response: ['Shedinja', 'Alolan Diglett', 'Diglett', 'Duskull', 'Shuckle']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    top_types = df['type1'].value_counts().head(2).index.tolist()
    return top_types
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    top_types = df['type1'].value_counts().head(2).index.tolist()
    return top_types
```
Response: ['Water', 'Normal']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    result = df[df['generation'] == 2].sort_values(by='attack', ascending=False).head(6)['name'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    result = df[df['generation'] == 2].sort_values(by='attack', ascending=False).head(6)['name'].tolist()
    return result
```
Response: ['Mega Heracross', 'Mega Tyranitar', 'Mega Scizor', 'Tyranitar', 'Ho-oh', 'Scizor']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary'] # Retain original column names 
    # The columns used in the solution : ['sp_defense']
    # The unique values of the columns used in the solution : 
    return df['sp_defense'].nlargest(5).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    # Retain original column names 
    # The columns used in the solution : ['sp_defense']
    # The unique values of the columns used in the solution : 
    return df['sp_defense'].nlargest(5).tolist()
```
Response: [250, 230, 200, 160, 160]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary'] # Retain original column names 
    result = df[df['legendary'] == True].nsmallest(2, 'defense')['defense'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    result = df[df['legendary'] == True].nsmallest(2, 'defense')['defense'].tolist()
    return result
```
Response: [20, 31]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    # The columns used in the solution : ['speed', 'generation']
    # The unique values of the columns used in the solution : 
    filtered_df = df[df['generation'] == 4]
    top_speeds = filtered_df.nlargest(2,'speed')['speed'].tolist()
    return top_speeds
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    filtered_df = df[df['generation'] == 4]
    top_speeds = filtered_df.nlargest(2,'speed')['speed'].tolist()
    return top_speeds
```
Response: [135, 127]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    result = df[~df['legendary']].nsmallest(6, 'total')['total'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['number', 'name', 'type1', 'type2', 'total', 'hp', 'attack', 'defense','sp_attack','sp_defense','speed', 'generation', 'legendary']
    result = df[~df['legendary']].nsmallest(6, 'total')['total'].tolist()
    return result
```
Response: [175, 180, 180, 185, 190, 194]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Extraversion'].max() > df['Agreeableness'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Extraversion'].max() > df['Agreeableness'].max()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_max_openness = df.loc[df['Openness'].idxmax()]['Profession']
    profession_max_conscientousness = df.loc[df['Conscientousness'].idxmax()]['Profession']
    return profession_max_openness == profession_max_conscientousness
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_max_openness = df.loc[df['Openness'].idxmax()]['Profession']
    profession_max_conscientousness = df.loc[df['Conscientousness'].idxmax()]['Profession']
    return profession_max_openness == profession_max_conscientousness
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    min_emotional_range_profession = df.loc[df['Emotional_Range'].idxmin()]['Profession']
    min_conversation_level = df['Conversation'].min()
    min_emotional_range_conversation = df.loc[df['Profession'] == min_emotional_range_profession, 'Conversation'].values[0]
    return min_emotional_range_conversation == min_conversation_level
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    min_emotional_range_profession = df.loc[df['Emotional_Range'].idxmin()]['Profession']
    min_conversation_level = df['Conversation'].min()
    min_emotional_range_conversation = df.loc[df['Profession'] == min_emotional_range_profession, 'Conversation'].values[0]
    return min_emotional_range_conversation == min_conversation_level
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    avg_openness_to_change = df['Openness to Change'].mean()
    avg_hedonism = df['Hedonism'].mean()
    return avg_openness_to_change > avg_hedonism
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    avg_openness_to_change = df['Openness to Change'].mean()
    avg_hedonism = df['Hedonism'].mean()
    return avg_openness_to_change > avg_hedonism
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Self-enhancement'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Self-enhancement'].max()
```
Response: 0.7826336180787501
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n'] # Retain original column names 
    return len(df[df['Emotional_Range'] > 0.5]['Profession'].unique())
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    return len(df[df['Emotional_Range'] > 0.5]['Profession'].unique())
```
Response: 1002
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_with_max_records = df.loc[df['n'].idxmax(), 'Profession']
    average_extraversion = df[df['Profession'] == profession_with_max_records]['Extraversion'].mean()
    return average_extraversion
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_with_max_records = df.loc[df['n'].idxmax(), 'Profession']
    average_extraversion = df[df['Profession'] == profession_with_max_records]['Extraversion'].mean()
    return average_extraversion
```
Response: 0.373214039767641
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Self-transcendence'].min()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Self-transcendence'].min()
```
Response: 0.035364139619357415
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_with_highest_conscientiousness = df.loc[df['Conscientousness'].idxmax(), 'Profession']
    return profession_with_highest_conscientiousness
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    profession_with_highest_conscientiousness = df.loc[df['Conscientousness'].idxmax(), 'Profession']
    return profession_with_highest_conscientiousness
```
Response: Policy Officer
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df.loc[df['Hedonism'].idxmin(), 'Profession']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df.loc[df['Hedonism'].idxmin(), 'Profession']
```
Response: Governor
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df.loc[df['Emotional_Range'].idxmax(), 'Profession']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df.loc[df['Emotional_Range'].idxmax(), 'Profession']
```
Response: Mortgage Banker
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df.loc[df['n'].idxmax(), 'Profession']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness_to_Change', 'Hedonism', 'Self_enhancement', 'Self_transcendence', 'n']
    return df.loc[df['n'].idxmax(), 'Profession']
```
Response: Program Manager
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_professions = df.groupby('Profession')['Openness'].mean().nlargest(3).index.tolist()
    return top_professions
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_professions = df.groupby('Profession')['Openness'].mean().nlargest(3).index.tolist()
    return top_professions
```
Response: ['Book Publisher', 'Bureau Chief', 'Publisher']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    bottom_4_professions = df.sort_values(by='Agreeableness').head(4)['Profession'].tolist()
    return bottom_4_professions
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    bottom_4_professions = df.sort_values(by='Agreeableness').head(4)['Profession'].tolist()
    return bottom_4_professions
```
Response: ['.Net Architect', 'Android Developer', 'Principal Engineer', 'Game Engineer']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_professions = df.sort_values(by='Conversation', ascending=False).head(5)['Profession'].tolist()
    return top_professions
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_professions = df.sort_values(by='Conversation', ascending=False).head(5)['Profession'].tolist()
    return top_professions
```
Response: ['Director of Athletics', 'Recruiting Coordinator', 'Athletic Coordinator', 'Director of Personnel', 'Skills Trainer']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    bottom_2_professions = df.nsmallest(2, 'Self-enhancement')['Profession'].tolist()
    return bottom_2_professions
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    bottom_2_professions = df.nsmallest(2, 'Self-enhancement')['Profession'].tolist()
    return bottom_2_professions
```
Response: ['U.S. Senator', 'Congressman']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_values = df['Openness to Change'].nlargest(3).tolist()
    return top_values
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    top_values = df['Openness to Change'].nlargest(3).tolist()
    return top_values
```
Response: [0.7557249985959847, 0.7413189187628788, 0.7034528053640179]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Emotional_Range'].nsmallest(4).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    return df['Emotional_Range'].nsmallest(4).tolist()
```
Response: [0.16523815696640565, 0.20054280643241226, 0.22155461168552476, 0.2506791678499942]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n'] # Retain original column names 
    return df['Extraversion'].nlargest(5).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    return df['Extraversion'].nlargest(5).tolist()
```
Response: [0.9794365922809227, 0.9723660656030668, 0.954299437125917, 0.9362989453985364, 0.9307917067583288]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n'] # Retain original column names 
    # The columns used in the solution : ['Self-transcendence']
    # The unique values of the columns used in the solution : 
    return df['Self-transcendence'].nsmallest(6).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    # Retain original column names 
    df.columns = ['Profession', 'Openness', 'Conscientousness', 'Extraversion', 'Agreeableness', 'Emotional_Range', 'Conversation', 'Openness to Change', 'Hedonism', 'Self-enhancement', 'Self-transcendence', 'n']
    # The columns used in the solution : ['Self-transcendence']
    # The unique values of the columns used in the solution : 
    return df['Self-transcendence'].nsmallest(6).tolist()
```
Response: [0.035364139619357415, 0.035579296052633214, 0.0399752446723049, 0.05732806625856246, 0.059109906308533855, 0.05927817925717627]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['title'].str.contains('communication', case=False).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['title'].str.contains('communication', case=False).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['organization'].str.contains('IBM').any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['organization'].str.contains('IBM').any()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['abstract'].str.contains('software', case=False).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['abstract'].str.contains('software', case=False).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return 'design' in df['type'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return 'design' in df['type'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return len(df['organization'].unique())
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return len(df['organization'].unique())
```
Response: 3575
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].mean()
```
Response: 14.745974597459746
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].max()
```
Response: 100
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return len(df[df['type'] == 'utility'])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return len(df[df['type'] == 'utility'])
```
Response: 8848
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.loc[df['num_claims'].idxmax(), 'organization']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.loc[df['num_claims'].idxmax(), 'organization']
```
Response: Massachusetts Institute of Technology
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['kind'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['kind'].mode()[0]
```
Response: B2
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['lang'].unique()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['lang'].unique()[0]
```
Response: en
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['graphext_cluster'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['graphext_cluster'].mode()[0]
```
Response: member, portion, body, end
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    top_orgs = df['organization'].value_counts().reset_index()
    top_orgs = top_orgs.sort_values(by=['count', 'organization'], ascending=[False, True])
    return top_orgs['organization'].head(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    top_orgs = df['organization'].value_counts().reset_index()
    top_orgs = top_orgs.sort_values(by=['count', 'organization'], ascending=[False, True])
    return top_orgs['organization'].head(3).tolist()
```
Response: ['International Business Machines Corporation', 'Samsung Electronics Co., Ltd.', 'Google Inc.']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['type'].value_counts().head(2).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['type'].value_counts().head(2).index.tolist()
```
Response: ['utility', 'design']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    kind_counts = df['kind'].value_counts().nlargest(2).index.tolist()
    return kind_counts
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    kind_counts = df['kind'].value_counts().nlargest(2).index.tolist()
    return kind_counts
```
Response: ['B2', 'S1']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    cluster_counts = df['graphext_cluster'].value_counts().reset_index()
    cluster_counts.columns = ['graphext_cluster', 'count']
    result = cluster_counts.sort_values(by=['count', 'graphext_cluster'], ascending=[True, False]).head(2)['graphext_cluster'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    cluster_counts = df['graphext_cluster'].value_counts().reset_index()
    cluster_counts.columns = ['graphext_cluster', 'count']
    result = cluster_counts.sort_values(by=['count', 'graphext_cluster'], ascending=[True, False]).head(2)['graphext_cluster'].tolist()
    return result
```
Response: ['habit, plant, foliage, flowers', 'soybean, plant, cultivar, soybean cultivar']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].nlargest(4).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df['num_claims'].nlargest(4).tolist()
```
Response: [100, 96, 93, 88]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.sort_values(by='num_claims', ascending=False).head(3)['id'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.sort_values(by='num_claims', ascending=False).head(3)['id'].tolist()
```
Response: [9479771.0, 9325365.0, 9323284.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    result = df[df['kind'].isin(['B2', 'S1'])].groupby('kind')['num_claims'].median().tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    result = df[df['kind'].isin(['B2', 'S1'])].groupby('kind')['num_claims'].median().tolist()
    return result
```
Response: [16.0, nan, 1.0, nan, nan, nan]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.sort_values(by='date', ascending=False)['id'].head(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['num_claims', 'organization', 'kind', 'type', 'graphext_cluster', 'date', 'abstract', 'title', 'lang', 'abstract_gx_ADJ', 'grp_title', 'abstract_gx_products', 'abstract_gx_organizations', 'abstract_gx_NOUN', 'abstract_gx_ngrams', 'id', 'target', 'weight', 'x', 'y']
    return df.sort_values(by='date', ascending=False)['id'].head(3).tolist()
```
Response: [9479476.0, nan, nan]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    max_followers = df['user_followers_count<gx:number>'].max()
    highest_follower_user = df[df['user_followers_count<gx:number>'] == max_followers]
    return highest_follower_user['user_verified<gx:boolean>'].values[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    max_followers = df['user_followers_count<gx:number>'].max()
    highest_follower_user = df[df['user_followers_count<gx:number>'] == max_followers]
    return highest_follower_user['user_verified<gx:boolean>'].values[0]
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    author_with_most_favorites = df.loc[df['user_favourites_count<gx:number>'].idxmax()]['author_id<gx:category>']
    author_with_most_retweets = df.loc[df['retweets<gx:number>'].idxmax()]['author_id<gx:category>']
    return author_with_most_favorites == author_with_most_retweets
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    author_with_most_favorites = df.loc[df['user_favourites_count<gx:number>'].idxmax()]['author_id<gx:category>']
    author_with_most_retweets = df.loc[df['retweets<gx:number>'].idxmax()]['author_id<gx:category>']
    return author_with_most_favorites == author_with_most_retweets
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    
    # Flatten the mention_names list and count occurrences
    mention_counts = df['mention_names<gx:list[category]>'].explode().value_counts()
    
    # Get the most mentioned user
    most_mentioned_user = mention_counts.idxmax()
    
    # Calculate total retweets for each mentioned user
    retweet_counts = df.explode('mention_names<gx:list[category]>').groupby('mention_names<gx:list[category]>')['retweets<gx:number>'].sum()
    
    # Get the most retweeted mentioned user
    most_retweeted_user = retweet_counts.idxmax()
    
    # Check if the most mentioned user is also the most retweeted mentioned user
    return most_mentioned_user == most_retweeted_user
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    
    # Flatten the mention_names list and count occurrences
    mention_counts = df['mention_names<gx:list[category]>'].explode().value_counts()
    
    # Get the most mentioned user
    most_mentioned_user = mention_counts.idxmax()
    
    # Calculate total retweets for each mentioned user
    retweet_counts = df.explode('mention_names<gx:list[category]>').groupby('mention_names<gx:list[category]>')['retweets<gx:number>'].sum()
    
    # Get the most retweeted mentioned user
    most_retweeted_user = retweet_counts.idxmax()
    
    # Check if the most mentioned user is also the most retweeted mentioned user
    return most_mentioned_user == most_retweeted_user
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    max_retweets_author = df.groupby('author_id<gx:category>')['retweets<gx:number>'].sum().idxmax()
    max_replies_author = df.groupby('author_id<gx:category>')['replies<gx:number>'].sum().idxmax()
    return max_retweets_author == max_replies_author
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    max_retweets_author = df.groupby('author_id<gx:category>')['retweets<gx:number>'].sum().idxmax()
    max_replies_author = df.groupby('author_id<gx:category>')['replies<gx:number>'].sum().idxmax()
    return max_retweets_author == max_replies_author
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['user_followers_count<gx:number>'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['user_followers_count<gx:number>'].max()
```
Response: 30308047
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    unique_authors_with_high_favorites = df[df['favorites<gx:number>'] > 10000]['author_id<gx:category>'].nunique()
    return unique_authors_with_high_favorites
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    unique_authors_with_high_favorites = df[df['favorites<gx:number>'] > 10000]['author_id<gx:category>'].nunique()
    return unique_authors_with_high_favorites
```
Response: 1
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['retweets<gx:number>'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['retweets<gx:number>'].max()
```
Response: 205169
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    mention_counts = df['mention_ids<gx:list[category]>'].explode().value_counts()
    return mention_counts.max() if not mention_counts.empty else 0
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    mention_counts = df['mention_ids<gx:list[category]>'].explode().value_counts()
    return mention_counts.max() if not mention_counts.empty else 0
```
Response: 22
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['user_followers_count<gx:number>'].idxmax(), 'author_name<gx:category>']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['user_followers_count<gx:number>'].idxmax(), 'author_name<gx:category>']
```
Response: Joe Biden
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['user_favourites_count<gx:number>'].idxmax(), 'author_name<gx:category>']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['user_favourites_count<gx:number>'].idxmax(), 'author_name<gx:category>']
```
Response: Joe Biden
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    mention_names = df['mention_names<gx:list[category]>'].explode()
    most_mentioned_user = mention_names.mode().iloc[0]
    return most_mentioned_user
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    mention_names = df['mention_names<gx:list[category]>'].explode()
    most_mentioned_user = mention_names.mode().iloc[0]
    return most_mentioned_user
```
Response: KamalaHarris
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['retweets<gx:number>'].idxmax(), 'author_name<gx:category>']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df.loc[df['retweets<gx:number>'].idxmax(), 'author_name<gx:category>']
```
Response: Joe Biden
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.sort_values(by='user_followers_count<gx:number>', ascending=False).head(3)['author_name<gx:category>'].tolist()
    return top_authors
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.sort_values(by='user_followers_count<gx:number>', ascending=False).head(3)['author_name<gx:category>'].tolist()
    return top_authors
```
Response: ['Joe Biden', 'Joe Biden', 'Joe Biden']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.groupby('author_name<gx:category>')['user_favourites_count<gx:number>'].sum().nlargest(4).index.tolist()
    return top_authors
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.groupby('author_name<gx:category>')['user_favourites_count<gx:number>'].sum().nlargest(4).index.tolist()
    return top_authors
```
Response: ['Joe Biden']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    from collections import Counter
    mentions = [name for names in df['mention_names<gx:list[category]>'] for name in names if name!= df.loc[df['mention_names<gx:list[category>']].apply(lambda x: name in x), 'author_name<gx:category>'].values[0]]
    top_mentions = Counter(mentions).most_common(4)
    return [name for name, count in top_mentions]
```python
import pandas as pd
from collections import Counter

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    mentions = [name for names in df['mention_names<gx:list[category]>'] for name in names if name!= df.loc[df['mention_names<gx:list[category>']].apply(lambda x: name in x), 'author_name<gx:category>'].values[0]]
    top_mentions = Counter(mentions).most_common(4)
    return [name for name, count in top_mentions]
```
Response: __CODE_ERROR__: unmatched ']' (<string>, line 3)
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.groupby('author_name<gx:category>')['retweets<gx:number>'].sum().nlargest(2).index.tolist()
    return top_authors
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    top_authors = df.groupby('author_name<gx:category>')['retweets<gx:number>'].sum().nlargest(2).index.tolist()
    return top_authors
```
Response: ['Joe Biden']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>'] # Retain original column names 
    # The columns used in the solution : ['user_followers_count<gx:number>']
    # The unique values of the columns used in the solution : 
    return df['user_followers_count<gx:number>'].nlargest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    return df['user_followers_count<gx:number>'].nlargest(3).tolist()
```
Response: [30308047, 30308047, 30308045]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>'] # Retain original column names 
    # The columns used in the solution : ['favorites']
    return df['favorites'].nlargest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>'] # Retain original column names 
    # The columns used in the solution : ['favorites']
    return df['favorites'].nlargest(3).tolist()
```
Response: __CODE_ERROR__: 'favorites'
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>'] # Retain original column names 
    mention_counts = df['mention_ids<gx:list[category]>'].explode().value_counts()
    top_5_mentions = mention_counts.dropna().head(5)
    return top_5_mentions.index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    mention_counts = df['mention_ids<gx:list[category]>'].explode().value_counts()
    top_5_mentions = mention_counts.dropna().head(5)
    return top_5_mentions.index.tolist()
```
Response: [np.int64(30354991), np.int64(821784477076750338), np.int64(21829541), np.int64(813286), np.int64(1129095209772552192)]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['retweets'].nlargest(2).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id<gx:category>', 'author_id<gx:category>', 'author_name<gx:category>', 'author_handler<gx:category>', 'author_avatar<gx:url>', 'user_created_at<gx:date>', 'user_description<gx:text>', 'user_favourites_count<gx:number>', 'user_followers_count<gx:number>', 'user_following_count<gx:number>', 'user_listed_count<gx:number>', 'user_tweets_count<gx:number>', 'user_verified<gx:boolean>', 'user_location<gx:text>', 'lang<gx:category>', 'type<gx:category>', 'text<gx:text>', 'date<gx:date>','mention_ids<gx:list[category]>','mention_names<gx:list[category]>','retweets<gx:number>', 'favorites<gx:number>','replies<gx:number>', 'quotes<gx:number>', 'links<gx:list[url]>', 'links_first<gx:url>', 'image_links<gx:list[url]>', 'image_links_first<gx:url>', 'rp_user_id<gx:category>', 'rp_user_name<gx:category>', 'location<gx:text>', 'tweet_link<gx:url>','source<gx:text>','search<gx:category>']
    return df['retweets'].nlargest(2).tolist()
```
Response: __CODE_ERROR__: 'retweets'
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    max_loan_amount = df['Loan Amount'].max()
    max_duration = df['Loan Duration - Months'].max()
    borrower_max_loan = df[df['Loan Amount'] == max_loan_amount]['Loan Duration - Months'].values[0]
    borrower_max_duration = df[df['Loan Duration - Months'] == max_duration]['Loan Amount'].values[0]
    return borrower_max_loan == max_duration and borrower_max_duration == max_loan_amount
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    max_loan_amount = df['Loan Amount'].max()
    max_duration = df['Loan Duration - Months'].max()
    borrower_max_loan = df[df['Loan Amount'] == max_loan_amount]['Loan Duration - Months'].values[0]
    borrower_max_duration = df[df['Loan Duration - Months'] == max_duration]['Loan Amount'].values[0]
    return borrower_max_loan == max_duration and borrower_max_duration == max_loan_amount
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    max_loans_borrower = df.loc[df['Number of Existing Loans'].idxmax()]
    max_amount_borrower = df.loc[df['Loan Amount'].idxmax()]
    return max_loans_borrower['Loan Amount'] == max_amount_borrower['Loan Amount']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    max_loans_borrower = df.loc[df['Number of Existing Loans'].idxmax()]
    max_amount_borrower = df.loc[df['Loan Amount'].idxmax()]
    return max_loans_borrower['Loan Amount'] == max_amount_borrower['Loan Amount']
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    longest_duration_borrower = df.loc[df['Loan Duration - Months'].idxmax()]
    max_existing_loans = df['Number of Existing Loans'].max()
    return longest_duration_borrower['Number of Existing Loans'] == max_existing_loans
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    longest_duration_borrower = df.loc[df['Loan Duration - Months'].idxmax()]
    max_existing_loans = df['Number of Existing Loans'].max()
    return longest_duration_borrower['Number of Existing Loans'] == max_existing_loans
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    oldest_borrower_age = df['Age'].max()
    oldest_borrower_loan_amount = df.loc[df['Age'] == oldest_borrower_age, 'Loan Amount'].max()
    highest_loan_amount = df['Loan Amount'].max()
    return oldest_borrower_loan_amount == highest_loan_amount
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    oldest_borrower_age = df['Age'].max()
    oldest_borrower_loan_amount = df.loc[df['Age'] == oldest_borrower_age, 'Loan Amount'].max()
    highest_loan_amount = df['Loan Amount'].max()
    return oldest_borrower_loan_amount == highest_loan_amount
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Amount'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Amount'].max()
```
Response: 18424
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return len(df[df['Number of Existing Loans'] > 1])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return len(df[df['Number of Existing Loans'] > 1])
```
Response: 367
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Duration - Months'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Duration - Months'].max()
```
Response: 72
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return len(df[df['Age'] > 50])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return len(df[df['Age'] > 50])
```
Response: 113
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Purpose of Loan'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Purpose of Loan'].mode()[0]
```
Response: Radio/TV
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Job'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Job'].mode()[0]
```
Response: Skilled
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Credit History'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Credit History'].mode()[0]
```
Response: Existing Credits Paid Back Duly Till Now
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Savings Account']
    # The unique values of the columns used in the solution : Column Savings Account has the following unique values: ['No Savings Account', 'Less than 100 DM', '500-1000 DM', 'More than 1000 DM', '100-500 DM']
    
    return df['Savings Account'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Savings Account']
    # The unique values of the columns used in the solution : Column Savings Account has the following unique values: ['No Savings Account', 'Less than 100 DM', '500-1000 DM', 'More than 1000 DM', '100-500 DM']
    
    return df['Savings Account'].mode()[0]
```
Response: Less than 100 DM
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    top_jobs = df.groupby('Job')['Loan Amount'].sum().nlargest(3).index.tolist()
    return top_jobs
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    top_jobs = df.groupby('Job')['Loan Amount'].sum().nlargest(3).index.tolist()
    return top_jobs
```
Response: ['Skilled', 'Highly Skilled', 'Unskilled - Resident']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    top_jobs = df.sort_values(by='Loan Duration - Months', ascending=False).head(4)['Job'].tolist()
    return top_jobs
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    top_jobs = df.sort_values(by='Loan Duration - Months', ascending=False).head(4)['Job'].tolist()
    return top_jobs
```
Response: ['Skilled', 'Skilled', 'Skilled', 'Highly Skilled']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    result = df.groupby('Job')['Number of Existing Loans'].sum().nlargest(5).index.tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    result = df.groupby('Job')['Number of Existing Loans'].sum().nlargest(5).index.tolist()
    return result
```
Response: ['Skilled', 'Unskilled - Resident', 'Highly Skilled', 'Unemployed / Unskilled  - Non-Resident']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Age', 'Job']
    # The unique values of the columns used in the solution : Column Job has the following unique values: ['Skilled', 'Unskilled - Resident', 'Highly Skilled', 'Unemployed / Unskilled  - Non-Resident']

    return df.sort_values(by='Age', ascending=False).head(2)['Job'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Age', 'Job']
    # The unique values of the columns used in the solution : Column Job has the following unique values: ['Skilled', 'Unskilled - Resident', 'Highly Skilled', 'Unemployed / Unskilled  - Non-Resident']

    return df.sort_values(by='Age', ascending=False).head(2)['Job'].tolist()
```
Response: ['Highly Skilled', 'Highly Skilled']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Amount'].nlargest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Loan Amount'].nlargest(3).tolist()
```
Response: [18424, 15945, 15857]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Loan Duration - Months']
    # The unique values of the columns used in the solution : 
    return df['Loan Duration - Months'].nlargest(4).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    # Retain original column names 
    # The columns used in the solution : ['Loan Duration - Months']
    # The unique values of the columns used in the solution : 
    return df['Loan Duration - Months'].nlargest(4).tolist()
```
Response: [72, 60, 60, 60]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Number of Existing Loans'].nlargest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status']
    return df['Number of Existing Loans'].nlargest(3).tolist()
```
Response: [4, 4, 4]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Loan Duration - Months', 'Credit History', 'Purpose of Loan', 'Loan Amount', 'Savings Account', 'Length of Current Employment', 'Installment Rate as % of Income', 'Guarantors', 'Length of Current Property Residence', 'Age', 'Housing', 'Number of Existing Loans', 'Job', 'Number of Dependants', 'Foreign Worker', 'Risk', 'Sex', 'Status'] # Retain original column names 
    # The columns used in the solution : ['Age']
    # The unique values of the columns used in the solution : 
    return df['Age'].nlargest(2).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    return df['Age'].nlargest(2).tolist()
```
Response: [75, 75]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df[df['Calories (kcal)'] == 0]['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df[df['Calories (kcal)'] == 0]['name'].tolist()
```
Response: []
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Sugar (g)'].gt(0).all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Sugar (g)'].gt(0).all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Fat (g)'].eq(0).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Fat (g)'].eq(0).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Protein (g)'].eq(0).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Protein (g)'].eq(0).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return len(df[df['Calories (kcal)'] > 500])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return len(df[df['Calories (kcal)'] > 500])
```
Response: 0
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Fat (g)'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Fat (g)'].mean()
```
Response: 0.08465
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return len(df[df['Sodium (g)'] > 1])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return len(df[df['Sodium (g)'] > 1])
```
Response: 18
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Protein (g)'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Protein (g)'].max()
```
Response: 0.2748
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Calories (kcal)'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Calories (kcal)'].idxmax(), 'name']
```
Response: bacon
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Total Sugar (g)'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Total Sugar (g)'].idxmax(), 'name']
```
Response: honey
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Total Fat (g)'].idxmin(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Total Fat (g)'].idxmin(), 'name']
```
Response: honey
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Protein (g)'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.loc[df['Protein (g)'].idxmax(), 'name']
```
Response: beef
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    top_5_calorie_foods = df.sort_values(by='Calories (kcal)', ascending=False).head(5)['name'].tolist()
    return top_5_calorie_foods
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    top_5_calorie_foods = df.sort_values(by='Calories (kcal)', ascending=False).head(5)['name'].tolist()
    return top_5_calorie_foods
```
Response: ['bacon', 'peanuts', 'chocolate bar', 'popcorn', 'cookie']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    top_3_least_sugar = df.sort_values(by='Total Sugar (g)').head(3)['name'].tolist()
    return top_3_least_sugar
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    top_3_least_sugar = df.sort_values(by='Total Sugar (g)').head(3)['name'].tolist()
    return top_3_least_sugar
```
Response: ['chicken', 'beef', 'cheese']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nlargest(4, 'Total Fat (g)')['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nlargest(4, 'Total Fat (g)')['name'].tolist()
```
Response: ['bacon', 'peanuts', 'cheese', 'popcorn']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.sort_values(by='Protein (g)').head(6)['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.sort_values(by='Protein (g)').head(6)['name'].tolist()
```
Response: ['candy', 'black tea', 'champagne', 'bacon', 'red wine', 'red apple']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Calories (kcal)'].nlargest(5).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Calories (kcal)'].nlargest(5).tolist()
```
Response: [8.98, 5.67, 5.18, 5.0, 4.97]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Sugar (g)'].nsmallest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df['Total Sugar (g)'].nsmallest(3).tolist()
```
Response: [0.0, 0.0, 0.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nlargest(4, 'Total Fat (g)')['Total Fat (g)'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nlargest(4, 'Total Fat (g)')['Total Fat (g)'].tolist()
```
Response: [0.995, 0.4924, 0.3099, 0.281]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nsmallest(6, 'Protein (g)')['Protein (g)'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['name', 'emoji', 'Calories (kcal)', 'Carbohydrates (g)', 'Total Sugar (g)', 'Protein (g)', 'Total Fat (g)', 'Saturated Fat (g)', 'Monounsaturated Fat (g)', 'Polyunsaturated Fat (g)', 'Total Fiber (g)', 'Cholesterol (mg)', 'Vitamin B6 (mg)', 'Vitamin A (IU)', 'Vitamin B12 (ug)', 'Vitamin C (mg)', 'Vitamin D (IU)', 'Vitamin E (IU)', 'Vitamin K (ug)', 'Thiamin (mg)', 'Riboflavin (mg)', 'Niacin (mg)', 'Folate (ug)', 'Pantothenic Acid (mg)', 'Choline (mg)', 'Calcium (g)', 'Copper (mg)', 'Iron (mg)', 'Magnesium (mg)', 'Manganese (mg)', 'Phosphorus (g)', 'Potassium (g)', 'Selenium (ug)', 'Sodium (g)', 'Zinc (mg)']
    return df.nsmallest(6, 'Protein (g)')['Protein (g)'].tolist()
```
Response: [0.0, 0.0, 0.0007, 0.0007, 0.0007, 0.002]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return 'Not completed Primary education' in df['edu'].values
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self-determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return 'Not completed Primary education' in df['edu'].values
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['polInterest'].isin(['Very interested', 'Somewhat interested']).all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['polInterest'].isin(['Very interested', 'Somewhat interested']).all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return 'No vote' in df['Vote Intention'].values
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return 'No vote' in df['Vote Intention'].values
```
Response: __CODE_ERROR__: The truth value of an empty array is ambiguous. Use `array.size > 0` to check that an array is not empty.
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self-placement on Left-Right economic values axis'].max() > 5
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self-placement on Left-Right economic values axis'].max() > 5
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return (df['User self- placement on Progressive-Conservative economic values axis'] == 10).sum()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return (df['User self- placement on Progressive-Conservative economic values axis'] == 10).sum()
```
Response: 372
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Age'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self-placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Age'].mean()
```
Response: 37.420120593188116
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['It should be more difficult for companies to lay off workers'].value_counts().get('SI', 0)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['It should be more difficult for companies to lay off workers'].value_counts().get('SI', 0)
```
Response: __CODE_ERROR__: Length mismatch: Expected axis has 45 elements, new values have 44 elements
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    max_age = df[df['gender'] == 'I prefer not to say']['Age'].max()
    return max_age
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    max_age = df[df['gender'] == 'I prefer not to say']['Age'].max()
    return max_age
```
Response: 105.0
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Vote Intention'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self-placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Vote Intention'].mode()[0]
```
Response: ['Ciudadanos']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['voteReason'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['voteReason'].mode()[0]
```
Response: The party ideas are close to my own
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['partyId'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['partyId'].mode()[0]
```
Response: Ciudadanos
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['lang'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['lang'].mode()[0]
```
Response: Castellano
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Vote Intention'].value_counts().head(5).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Vote Intention'].value_counts().head(5).index.tolist()
```
Response: [array(['Ciudadanos'], dtype=object), array(['I am undeceided'], dtype=object), array(['Podemos'], dtype=object), array(['PP'], dtype=object), array(['I prefer not to say'], dtype=object)]
--------------------
import pandas as pd
from collections import Counter

def answer(df: pd.DataFrame) -> list:
    vote_reasons = df['voteReason'].dropna().tolist()
    reason_counts = Counter(vote_reasons)
    top_3_reasons = reason_counts.most_common(3)
    return [reason for reason, count in top_3_reasons]
```python
import pandas as pd
from collections import Counter

def answer(df: pd.DataFrame) -> list:
    vote_reasons = df['voteReason'].dropna().tolist()
    reason_counts = Counter(vote_reasons)
    top_3_reasons = reason_counts.most_common(3)
    return [reason for reason, count in top_3_reasons]
```
Response: __CODE_ERROR__: name 'Counter' is not defined
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['partyId'].value_counts().head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['partyId'].value_counts().head(3).index.tolist()
```
Response: ['Ciudadanos', 'PP', 'I prefer not to say']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['edu'].value_counts().head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['edu'].value_counts().head(3).index.tolist()
```
Response: ['University degree', 'Postgraduate degree', 'Technical/Vocational education']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    age_counts = df['Age'].value_counts()
    return age_counts.head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    age_counts = df['Age'].value_counts()
    return age_counts.head(3).index.tolist()
```
Response: [38.0, 23.0, 39.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self-placement on Left-Right economic values axis'].value_counts().head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self-placement on Left-Right economic values axis'].value_counts().head(3).index.tolist()
```
Response: [5.0, 3.0, 6.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self- placement on Progressive-Conservative economic values axis'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['User self- placement on Progressive-Conservative economic values axis'].value_counts().head(4).index.tolist()
```
Response: [5.0, 3.0, 4.0, 0.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self- determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Constitutional organisation of the country (More Descentralization)'].value_counts().head(2).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Vote Intention', 'Age', 'const', 'edu', 'gender', 'lang', 'partyId', 'polInterest', 'prevVote', 'prevVoteCat', 'prov', 'Austerity politics are needed in order to overcome the crisis', 'The growth of Islam is a threat to the security of Spain', 'The church must pay the IBI', 'The fact that gay couples can adopt children is positive for society', 'Women should choose freely on issues of abortion', 'The immigration detention centres (CIES) should be closed', 'Schools segregated by sex should also be subsidized by the state', 'Spain must tighten its immigration policy', 'Bullfights in Spain should be banned', "The 'gag law' is necessary to avoid social unrest", 'In order to fight organized crime, restrictions on civil rights and liberties must be accepted', 'Efficiency in the delivery of public services will be improved with private sector participation', 'Negotiations with ETA weaken the state', 'The political party that receives the most votes should govern', 'Decentralizati on in Spain is inadequate and should continue to expand', 'Linguistic policy in the autonomous regions discriminates against Spanish language', 'The central government should control the spending of regional governments to limit their indebtedness', 'The possibility of a referendum on self-determination of any Autonomous Community must be recognized by the Constitution', 'The 1978 Constitution is the appropriate framework for our society', 'Navarra and the Basque Country should retain their tax system', 'Catalonia must be recognized as a nation', 'The government should take a tougher line against the persecution of opposition leaders in Venezuela', 'The number of public sector workers should be increased', 'The European Union must do more to support the Greek economy', 'It should be more difficult for companies to lay off workers', 'Bailing out banks is needed in order to restore economic stability', 'Increasing university fees is necessary for the sustainability of the university system', 'The government should subsidize clean energy in order to encourage its use', 'The subject of religion should be part of the curriculum', 'The decriminalizati on of soft drugs for personal use is a positive measure', 'User self-placement on Left-Right economic values axis', 'User self- placement on Progressive-Conservative economic values axis', 'Constitutional organisation of the country (More Descentralization)', 'voteReason']
    return df['Constitutional organisation of the country (More Descentralization)'].value_counts().head(2).index.tolist()
```
Response: [2.0, 3.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return 'No - I will not register' in df['Are you registered to vote?'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return 'No - I will not register' in df['Are you registered to vote?'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df[(df['Did you vote in the 2016 Presidential election? (Four years ago)'] == 'Yes') & (df['How likely are you to vote in the forthcoming US Presidential election? Early Voting Open'] < 1)].shape[0] > 0
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df[(df['Did you vote in the 2016 Presidential election? (Four years ago)'] == 'Yes') & (df['How likely are you to vote in the forthcoming US Presidential election? Early Voting Open'] < 1)].shape[0] > 0
```
Response: __CODE_ERROR__: Unordered Categoricals can only compare equality or not
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    result = df[(df['Did you vote in the 2016 Presidential election? (Four years ago)'].str.contains('No')) & (df['How likely are you to vote in the forthcoming US Presidential election? Early Voting Open']!= 'Not at all likely')]
    return len(result)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    result = df[(df['Did you vote in the 2016 Presidential election? (Four years ago)'].str.contains('No')) & (df['How likely are you to vote in the forthcoming US Presidential election? Early Voting Open']!= 'Not at all likely')]
    return len(result)
```
Response: 807
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    shifted_preferences = df[df['Who did you vote for?']!= df['Who did you vote for in the 2016 Presidential election? (Four years ago)']]
    return not shifted_preferences.empty
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    shifted_preferences = df[df['Who did you vote for?']!= df['Who did you vote for in the 2016 Presidential election? (Four years ago)']]
    return not shifted_preferences.empty
```
Response: __CODE_ERROR__: Categoricals can only be compared if 'categories' are the same.
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    eligible_to_vote = df[df['Are you registered to vote?'].isin(['Yes', 'No - but I will register']) & (df['Are you registered to vote? Not open to vote'] == 'No')]
    return len(eligible_to_vote)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    eligible_to_vote = df[(df['Are you registered to vote?'].isin(['Yes', 'No - but I will register'])) & (df['Are you registered to vote? Not open to vote'] == 'No')]
    return len(eligible_to_vote)
```
Response: 0
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return (df['Who are you most likely to vote for on election day?'] == 'Joe Biden (Democrat)').sum()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return (df['Who are you most likely to vote for on election day?'] == 'Joe Biden (Democrat)').sum()
```
Response: 799
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    high_school_or_less = df[df['What is the highest degree or level of school you have *completed*?'].isin(['Less than high school', 'High school graduate'])]
    return len(high_school_or_less)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    high_school_or_less = df[df['What is the highest degree or level of school you have *completed*?'].isin(['Less than high school', 'High school graduate'])]
    return len(high_school_or_less)
```
Response: 0
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    regions_adjacent_to_south_atlantic = ['Southeast', 'Northeast']
    return df[df['Region'].isin(regions_adjacent_to_south_atlantic)].shape[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    regions_adjacent_to_south_atlantic = ['Southeast', 'Northeast']
    return df[df['Region'].isin(regions_adjacent_to_south_atlantic)].shape[0]
```
Response: 652
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    age_columns = ['How old are you?', 'Again, for statistical purposes only, what is your age?']
    combined_ages = pd.concat([df[col] for col in age_columns if col in df.columns])
    return combined_ages.mode().iloc[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    age_columns = ['How old are you?', 'Again, for statistical purposes only, what is your age?']
    combined_ages = pd.concat([df[col] for col in age_columns if col in df.columns])
    return combined_ages.mode().iloc[0]
```
Response: 65+
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    choices = df['Who are you most likely to vote for on election day?'].value_counts().drop('Undecided')
    return choices.idxmax() if not choices.empty else 'No clear preference'
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    choices = df['Who are you most likely to vote for on election day?'].value_counts().drop('Undecided', errors='ignore')
    return choices.idxmax() if not choices.empty else 'No clear preference'
```
Response: Donald Trump (Republican)
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['What is the highest degree or level of school you have *completed*?'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['What is the highest degree or level of school you have *completed*?'].mode()[0]
```
Response: Some college, no degree
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    division_counts = df['Division'].value_counts()
    max_count = division_counts.max()
    divisions_with_max_count = division_counts[division_counts == max_count].index.tolist()
    return sorted(divisions_with_max_count, reverse=True)[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    division_counts = df['Division'].value_counts()
    max_count = division_counts.max()
    divisions_with_max_count = division_counts[division_counts == max_count].index.tolist()
    return sorted(divisions_with_max_count, reverse=True)[0]
```
Response: South Atlantic
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    state_counts = df['State'].value_counts().head(6)
    return state_counts.index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    state_counts = df['State'].value_counts().head(6)
    return state_counts.index.tolist()
```
Response: ['CA', 'TX', 'NY', 'FL', 'GA', 'PA']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    profession_counts = df['Which of these best describes the kind of work you do?'].value_counts()
    common_professions = profession_counts.nlargest(2)
    return sorted(common_professions.index)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    profession_counts = df['Which of these best describes the kind of work you do?'].value_counts()
    common_professions = profession_counts.nlargest(2)
    return sorted(common_professions.index)
```
Response: ['Healthcare', 'Other']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    top_groups = df['race_ethnicity_grouped'].value_counts().nlargest(2).index.tolist()
    return top_groups
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    top_groups = df['race_ethnicity_grouped'].value_counts().nlargest(2).index.tolist()
    return top_groups
```
Response: ['White', 'BlackOrAfricanAmerican']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter'] # Retain original column names 
    age_counts = df['Again, for statistical purposes only, what is your age?'].value_counts()
    return age_counts.head(6).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    age_counts = df['Again, for statistical purposes only, what is your age?'].value_counts()
    return age_counts.head(6).index.tolist()
```
Response: ['65+', '55-64', '45-54', '35-44', '18-24', '25-34']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    unique_counties = df['County FIPS'].unique()
    sorted_unique_counties = sorted(unique_counties)
    return sorted_unique_counties[-3:]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    unique_counties = df['County FIPS'].unique()
    sorted_unique_counties = sorted(unique_counties)
    return sorted_unique_counties[-3:]
```
Response: [np.uint16(56021), np.uint16(56025), np.uint16(56031)]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['Weight'].unique().tolist()[-4:]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['Weight'].unique().tolist()[-4:]
```
Response: [4.421046589740907, 0.9618281410691866, 0.3403369965220294, 1.915612397160496]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['NCHS Urban/rural'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['NCHS Urban/rural'].value_counts().head(4).index.tolist()
```
Response: [1, 2, 3, 4]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['likelihood'].value_counts().head(2).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'Weight', 'NCHS Urban/rural', 'Division', 'Wave', 'Start time', 'County FIPS', 'How old are you?', 'Are you', "Would you say you follow what's going on in government and public affairs", 'Are you registered to vote?', 'Are you registered to vote? Not open to vote', 'How likely are you to vote in the forthcoming US Presidential election? Early Voting Open', 'Headline vote share (intention and already voted combined)', 'Who did you vote for?', 'Who are you most likely to vote for on election day?', 'Did you vote in the 2016 Presidential election? (Four years ago)', 'Who did you vote for in the 2016 Presidential election? (Four years ago)', 'Which of the following best describes your ethnic heritage?', 'What is the highest degree or level of school you have *completed*?', 'Which of the following best describes your current employment status?', 'What was your yearly household income at the end of last year (before tax)?', 'If you had to choose a candidate today, who would you vote for?', 'Again, for statistical purposes only, what is your age?', 'State', 'Region', 'To what extent do you agree or disagree that the election will be fair, and you will trust the result?', 'How confident are you in the security and effectiveness of mail-in ballots when voting for president?', 'In the event of being declared the loser, should {answer:Candidate} accept or challenge the result?', 'If you have any concerns about the US election, what are they? - Contracting Covid-19 at a polling station', 'If you have any concerns about the US election, what are they? - Mail-in or in-person voter fraud', 'If you have any concerns about the US election, what are they? - Polling place reduction and changes', 'If you have any concerns about the US election, what are they? - Long wait times at polling place', 'If you have any concerns about the US election, what are they? - Voter intimidation at polling place', 'If you have any concerns about the US election, what are they? - Foreign interference/influence on the election', 'If you have any concerns about the US election, what are they? - The losing candidate not accepting the result', 'If you have any concerns about the US election, what are they? - Fake news/ disinformation', 'If you have any concerns about the US election, what are they? - Other', 'If you have any concerns about the US election, what are they? - I don’t have any specific concerns about the election', 'Which of these best describes the kind of work you do?', 'likelihood', 'NCHS Urban/rural (long form)', 'Local time', 'race_ethnicity_grouped', 'education_grouped_by_gender', 'weight_by_2016_vote', 'vote_choice', 'age_by_gender','region_x_gender','simple_2016_vote', 'likely_voter', 'likely_decided_voter']
    return df['likelihood'].value_counts().head(2).index.tolist()
```
Response: [10.0, 11.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Golf' in df['model'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Golf' in df['model'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Autos Raymara' in df['dealer'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Autos Raymara' in df['dealer'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['version'].str.contains('BMW', na=False).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['version'].str.contains('BMW', na=False).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Manual' in df['shift'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return 'Manual' in df['shift'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['model'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['model'].nunique()
```
Response: 940
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['photos'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['photos'].mean()
```
Response: 16.19912
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['price'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['price'].max()
```
Response: 549900
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return len(df[df['year'] == 2020])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return len(df[df['year'] == 2020])
```
Response: 4237
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df.loc[df['price'].idxmax(), 'dealer']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df.loc[df['price'].idxmax(), 'dealer']
```
Response: Supergarage
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    make_counts = df['make'].value_counts()
    max_count = make_counts.max()
    most_common_makes = make_counts[make_counts == max_count].index.tolist()
    return sorted(most_common_makes)[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    make_counts = df['make'].value_counts()
    max_count = make_counts.max()
    most_common_makes = make_counts[make_counts == max_count].index.tolist()
    return sorted(most_common_makes)[0]
```
Response: VOLKSWAGEN
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['fuel'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['fuel'].mode()[0]
```
Response: Diésel
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    province_counts = df['province'].value_counts()
    return province_counts.idxmax()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    province_counts = df['province'].value_counts()
    return province_counts.idxmax()
```
Response: Madrid
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    province_counts = df['province'].value_counts().reset_index()
    province_counts.columns = ['province', 'count']
    top_provinces = province_counts.sort_values(by=['count', 'province'], ascending=[False, False]).head(3)
    return top_provinces['province'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    province_counts = df['province'].value_counts().reset_index()
    province_counts.columns = ['province', 'count']
    top_provinces = province_counts.sort_values(by=['count', 'province'], ascending=[False, False]).head(3)
    return top_provinces['province'].tolist()
```
Response: ['Madrid', 'Barcelona', 'Valencia']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    # The columns used in the solution : ['color']
    # The unique values of the columns used in the solution : 
    color_counts = df['color'].value_counts()
    return color_counts.head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    color_counts = df['color'].value_counts()
    return color_counts.head(3).index.tolist()
```
Response: ['Blanco', 'Gris / Plata', 'Negro']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['make'].value_counts().head(5).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['make'].value_counts().head(5).index.tolist()
```
Response: ['VOLKSWAGEN', 'BMW', 'MERCEDES-BENZ', 'AUDI', 'PEUGEOT']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    least_common_fuels = df['fuel'].value_counts().nsmallest(2).index.tolist()
    return least_common_fuels
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    least_common_fuels = df['fuel'].value_counts().nsmallest(2).index.tolist()
    return least_common_fuels
```
Response: ['Gas natural (CNG)', 'Gas licuado (GLP)']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['year'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['year'].value_counts().head(4).index.tolist()
```
Response: [2016.0, 2017.0, 2019.0, 2020.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['kms'].nlargest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['kms'].nlargest(3).tolist()
```
Response: [5000000, 4000006, 3500000]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    top_5_photos = df.nlargest(5, 'photos')['photos'].tolist()
    return top_5_photos
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    top_5_photos = df.nlargest(5, 'photos')['photos'].tolist()
    return top_5_photos
```
Response: [54, 54, 54, 54, 54]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['power'].nlargest(6).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['url', 'company','make','model','version', 'price', 'price_financed', 'fuel', 'year', 'kms', 'power', 'doors','shift', 'color', 'photos', 'is_professional', 'dealer', 'province', 'country', 'publish_date', 'insert_date']
    return df['power'].nlargest(6).tolist()
```
Response: [800.0, 800.0, 796.0, 772.0, 720.0, 720.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['Transaction'].is_unique
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['Transaction'].is_unique
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return 'night' in df['period_day'].values
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return 'night' in df['period_day'].values
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # Check if all items have transactions on weekdays
    items_with_weekday_transactions = set(df[df['weekday_weekend'] == 'weekday']['Item'].unique())
    all_items = set(df['Item'].unique())
    return items_with_weekday_transactions == all_items
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # Check if all items have transactions on weekdays
    items_with_weekday_transactions = set(df[df['weekday_weekend'] == 'weekday']['Item'].unique())
    all_items = set(df['Item'].unique())
    return items_with_weekday_transactions == all_items
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # The columns used in the solution : ['Transaction', 'period_day', 'weekday_weekend']
    # The unique values of the columns used in the solution : Column weekday_weekend has the following unique values: ['weekend', 'weekday']
    
    evening_transactions_on_weekends = df[(df['weekday_weekend'] == 'weekend') & (df['period_day'] == 'evening')]
    return not evening_transactions_on_weekends.empty
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    evening_transactions_on_weekends = df[(df['weekday_weekend'] == 'weekend') & (df['period_day'] == 'evening')]
    return not evening_transactions_on_weekends.empty
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return len(df['Item'].unique())
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return len(df['Item'].unique())
```
Response: 94
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['date_time'].dt.date.nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['date_time'].dt.date.nunique()
```
Response: __CODE_ERROR__: Can only use .dt accessor with datetimelike values
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['Transaction'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['Transaction'].max()
```
Response: 9684
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return len(df[df['period_day'] == 'afternoon']['Transaction'].unique())
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return len(df[df['period_day'] == 'afternoon']['Transaction'].unique())
```
Response: 5089
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df.groupby('period_day')['Transaction'].nunique().idxmax()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df.groupby('period_day')['Transaction'].nunique().idxmax()
    return result
```
Response: afternoon
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # The columns used in the solution : ['Item', 'weekday_weekend']
    # The unique values of the columns used in the solution : Column weekday_weekend has the following unique values: ['weekend', 'weekday']
    
    weekday_df = df[df['weekday_weekend'] == 'weekday']
    most_common_item = weekday_df['Item'].mode()[0]
    return most_common_item
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    weekday_df = df[df['weekday_weekend'] == 'weekday']
    most_common_item = weekday_df['Item'].mode()[0]
    return most_common_item
```
Response: Coffee
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    weekday_df = df[df['weekday_weekend'] == 'weekday']
    least_popular_item = weekday_df['Item'].value_counts().idxmin()
    return least_popular_item
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    weekday_df = df[df['weekday_weekend'] == 'weekday']
    least_popular_item = weekday_df['Item'].value_counts().idxmin()
    return least_popular_item
```
Response: Chicken sand
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    brownie_sales = df[df['Item'] == 'Brownie']
    most_frequent_period = brownie_sales['period_day'].mode()[0]
    return most_frequent_period
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    brownie_sales = df[df['Item'] == 'Brownie']
    most_frequent_period = brownie_sales['period_day'].mode()[0]
    return most_frequent_period
```
Response: afternoon
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    morning_items = df[df['period_day'] =='morning']['Item']
    top_items = morning_items.value_counts().head(3).index.tolist()
    return top_items
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    morning_items = df[df['period_day'] =='morning']['Item']
    top_items = morning_items.value_counts().head(3).index.tolist()
    return top_items
```
Response: ['Coffee', 'Bread', 'Pastry']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    top_items = df[df['period_day'] == 'afternoon']['Item'].value_counts().head(2).index.tolist()
    return top_items
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    top_items = df[df['period_day'] == 'afternoon']['Item'].value_counts().head(2).index.tolist()
    return top_items
```
Response: ['Coffee', 'Bread']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # The columns used in the solution : ['Item', 'weekday_weekend']
    # The unique values of the columns used in the solution : Column weekday_weekend has the following unique values: ['weekend', 'weekday']
    
    weekend_sales = df[df['weekday_weekend'] == 'weekend']
    item_counts = weekend_sales['Item'].value_counts()
    top_items = item_counts.nlargest(2).index.tolist()
    if len(top_items) < 2 or item_counts[top_items[0]]!= item_counts[top_items[1]]:
        return top_items
    else:
        return sorted(top_items)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # The columns used in the solution : ['Item', 'weekday_weekend']
    # The unique values of the columns used in the solution : Column weekday_weekend has the following unique values: ['weekend', 'weekday']
    
    weekend_sales = df[df['weekday_weekend'] == 'weekend']
    item_counts = weekend_sales['Item'].value_counts()
    top_items = item_counts.nlargest(2).index.tolist()
    if len(top_items) < 2 or item_counts[top_items[0]]!= item_counts[top_items[1]]:
        return top_items
    else:
        return sorted(top_items)
```
Response: ['Coffee', 'Bread']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['period_day'] == 'evening']['Item'].value_counts().reset_index()
    filtered_items = result[result['count'] == 2]['Item'].tolist()
    return filtered_items[:4]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['period_day'] == 'evening']['Item'].value_counts().reset_index()
    filtered_items = result[result['count'] == 2]['Item'].tolist()
    return filtered_items[:4]
```
Response: ['Vegan mincepie', 'Mortimer', 'Art Tray', 'Mighty Protein']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    transaction_counts = df['Transaction'].value_counts()
    top_transactions = transaction_counts.head(4).index.tolist()
    return top_transactions
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    transaction_counts = df['Transaction'].value_counts()
    top_transactions = transaction_counts.head(4).index.tolist()
    return top_transactions
```
Response: [6279, 6412, 6716, 6474]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    # The columns used in the solution : ['Transaction']
    # The unique values of the columns used in the solution : 
    return df['Transaction'].nlargest(5).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    return df['Transaction'].nlargest(5).tolist()
```
Response: [9684, 9683, 9683, 9682, 9682]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['Item'] == 'Bread']['Transaction'].nlargest(4).tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['Item'] == 'Bread']['Transaction'].nlargest(4).tolist()
    return result
```
Response: [9680, 9679, 9673, 9671]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['period_day'] =='morning'].sort_values(by='Transaction').head(2)['Transaction'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Transaction', 'Item', 'date_time', 'period_day', 'weekday_weekend']
    result = df[df['period_day'] =='morning'].sort_values(by='Transaction').head(2)['Transaction'].tolist()
    return result
```
Response: [1, 2]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    # The columns used in the solution : ['Rating', 'Reviewer_Location']
    # The unique values of the columns used in the solution : 
    australia_reviews = df[df['Reviewer_Location'] == 'Australia']
    return all(australia_reviews['Rating'] > 3)
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    australia_reviews = df[df['Reviewer_Location'] == 'Australia']
    return all(australia_reviews['Rating'] > 3)
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_counts = df['Branch'].value_counts()
    most_reviewed_branch = branch_counts.idxmax()
    return most_reviewed_branch == 'Disneyland_HongKong'
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_counts = df['Branch'].value_counts()
    most_reviewed_branch = branch_counts.idxmax()
    return most_reviewed_branch == 'Disneyland_HongKong'
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return (df['Rating'] == 1).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return (df['Rating'] == 1).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df[df['Rating'] == 5]['Reviewer_Location'].nunique() == df['Reviewer_Location'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df[df['Rating'] == 5]['Reviewer_Location'].nunique() == df['Reviewer_Location'].nunique()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Reviewer_Location'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Reviewer_Location'].nunique()
```
Response: 162
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    # The columns used in the solution : ['Rating', 'Branch']
    # The unique values of the columns used in the solution : Column Branch has the following unique values: ['Disneyland_HongKong', 'Disneyland_California', 'Disneyland_Paris']
    
    average_rating = df[df['Branch'] == 'Disneyland_HongKong']['Rating'].mean()
    return average_rating
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    average_rating = df[df['Branch'] == 'Disneyland_HongKong']['Rating'].mean()
    return average_rating
```
Response: 4.204158004158004
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Review_ID'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Review_ID'].max()
```
Response: 670801367
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    # The columns used in the solution : ['Year_Month']
    # The unique values of the columns used in the solution : 
    return df[df['Year_Month'].str.startswith('2019')].shape[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df[df['Year_Month'].str.startswith('2019')].shape[0]
```
Response: 786
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Reviewer_Location'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    return df['Reviewer_Location'].mode()[0]
```
Response: United States
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_avg_rating = df.groupby('Branch')['Rating'].mean()
    return branch_avg_rating.idxmin()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_avg_rating = df.groupby('Branch')['Rating'].mean()
    return branch_avg_rating.idxmin()
```
Response: Disneyland_Paris
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    # The columns used in the solution : ['Rating', 'Year_Month']
    # The unique values of the columns used in the solution : 
    first_negative_review = df[df['Rating'] == 1].sort_values(by='Year_Month').head(1)
    return first_negative_review['Year_Month'].values[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    first_negative_review = df[df['Rating'] == 1].sort_values(by='Year_Month').head(1)
    return first_negative_review['Year_Month'].values[0]
```
Response: 2019-4
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    avg_ratings = df.groupby('Reviewer_Location')['Rating'].mean().reset_index()
    max_avg_rating = avg_ratings['Rating'].max()
    locations_with_max_avg = avg_ratings[avg_ratings['Rating'] == max_avg_rating]
    return locations_with_max_avg.sort_values(by='Reviewer_Location').iloc[0]['Reviewer_Location']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    avg_ratings = df.groupby('Reviewer_Location')['Rating'].mean().reset_index()
    max_avg_rating = avg_ratings['Rating'].max()
    locations_with_max_avg = avg_ratings[avg_ratings['Rating'] == max_avg_rating]
    return locations_with_max_avg.sort_values(by='Reviewer_Location').iloc[0]['Reviewer_Location']
```
Response: Mali
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    top_locations = df['Reviewer_Location'].value_counts().head(3).index.tolist()
    return top_locations
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    top_locations = df['Reviewer_Location'].value_counts().head(3).index.tolist()
    return top_locations
```
Response: ['United States', 'United Kingdom', 'Australia']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_avg_rating = df.groupby('Branch')['Rating'].mean().reset_index()
    bottom_2_branches = branch_avg_rating.nsmallest(2, 'Rating')['Branch'].tolist()
    return bottom_2_branches
```python
import pandas as pd

def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    branch_avg_rating = df.groupby('Branch')['Rating'].mean().reset_index()
    bottom_2_branches = branch_avg_rating.nsmallest(2, 'Rating')['Branch'].tolist()
    return bottom_2_branches
```
Response: ['Disneyland_Paris', 'Disneyland_HongKong']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    review_counts = df['Year_Month'].value_counts().sort_values(ascending=False)
    top_4_dates = review_counts.head(4).index.tolist()
    return top_4_dates
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    review_counts = df['Year_Month'].value_counts().sort_values(ascending=False)
    top_4_dates = review_counts.head(4).index.tolist()
    return top_4_dates
```
Response: ['missing', '2015-8', '2015-7', '2015-12']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.groupby('Reviewer_Location')['Rating'].mean().nsmallest(3).index.tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.groupby('Reviewer_Location')['Rating'].mean().nsmallest(3).index.tolist()
    return result
```
Response: ['Turks and Caicos Islands', 'South Sudan', 'Suriname']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.sort_values(by=['Rating', 'Review_ID'], ascending=[False, False]).head(5)
    return result['Review_ID'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.sort_values(by=['Rating', 'Review_ID'], ascending=[False, False]).head(5)
    return result['Review_ID'].tolist()
```
Response: [670801367, 670760708, 670721950, 670606796, 670585330]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.sort_values(by=['Rating', 'Review_ID']).head(4)['Review_ID'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    result = df.sort_values(by=['Rating', 'Review_ID']).head(4)['Review_ID'].tolist()
    return result
```
Response: [1534364, 2718239, 2831747, 2945119]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    top_ratings = df[df['Reviewer_Location'] == 'Australia']['Rating'].head(3).tolist()
    return top_ratings
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    top_ratings = df[df['Reviewer_Location'] == 'Australia']['Rating'].head(3).tolist()
    return top_ratings
```
Response: [4, 4, 2]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    # The columns used in the solution : ['Rating']
    # The unique values of the columns used in the solution : 
    lowest_ratings = df[df['Branch'] == 'Disneyland_HongKong'].nsmallest(2, 'Rating')['Rating'].tolist()
    return lowest_ratings
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['Review_ID', 'Rating', 'Year_Month', 'Reviewer_Location', 'Review_Text', 'Branch']
    lowest_ratings = df[df['Branch'] == 'Disneyland_HongKong'].nsmallest(2, 'Rating')['Rating'].tolist()
    return lowest_ratings
```
Response: [1, 1]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['lang'].eq('en').all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['lang'].eq('en').all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].sum() > 0
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].sum() > 0
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return (df['retweets'] > 10000).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return (df['retweets'] > 10000).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return (df['favorites'] > 50000).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return (df['favorites'] > 50000).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['author_id'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['author_id'].nunique()
```
Response: 1
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].mean()
```
Response: 8774.52044683822
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['favorites'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['favorites'].max()
```
Response: 589793
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    df['date'] = pd.to_datetime(df['date'])
    return (df['date'].dt.year == 2018).sum()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    df['date'] = pd.to_datetime(df['date'])
    return (df['date'].dt.year == 2018).sum()
```
Response: 2891
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['author_name'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['author_name'].mode()[0]
```
Response: Donald J. Trump
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df.loc[df['favorites'].idxmax(), 'text']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df.loc[df['favorites'].idxmax(), 'text']
```
Response: Such a beautiful and important evening! The forgotten man and woman will never be forgotten again. We will all come together as never before
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    max_retweets_lang = df.loc[df['retweets'].idxmax(), 'lang']
    return max_retweets_lang
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    max_retweets_lang = df.loc[df['retweets'].idxmax(), 'lang']
    return max_retweets_lang
```
Response: und
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['lang'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['lang'].mode()[0]
```
Response: en
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    # The columns used in the solution : ['author_handler']
    
    top_handlers = df['author_handler'].value_counts().head(3).index.tolist()
    return top_handlers
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    # The columns used in the solution : ['author_handler']
    
    top_handlers = df['author_handler'].value_counts().head(3).index.tolist()
    return top_handlers
```
Response: ['realDonaldTrump']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    lang_counts = df['lang'].value_counts().reset_index()
    lang_counts.columns = ['lang', 'count']
    filtered_langs = lang_counts[lang_counts['lang'].str.startswith('p')]
    sorted_langs = pd.concat([filtered_langs.sort_values(by='count').head(2), lang_counts[~lang_counts['lang'].isin(filtered_langs['lang'])].sort_values(by='count').head(2)])
    return sorted_langs['lang'].tolist()[:2]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    lang_counts = df['lang'].value_counts().reset_index()
    lang_counts.columns = ['lang', 'count']
    filtered_langs = lang_counts[lang_counts['lang'].str.startswith('p')]
    sorted_langs = pd.concat([filtered_langs.sort_values(by='count').head(2), lang_counts[~lang_counts['lang'].isin(filtered_langs['lang'])].sort_values(by='count').head(2)])
    return sorted_langs['lang'].tolist()[:2]
```
Response: ['pt', 'pl']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    mention_counts = df['mention_names'].str.split(', ').explode().value_counts()
    return mention_counts.head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    mention_counts = df['mention_names'].str.split(', ').explode().value_counts()
    return mention_counts.head(4).index.tolist()
```
Response: []
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    tweet_count = df.groupby('author_name').size().reset_index(name='tweet_count')
    bottom_3_authors = tweet_count.nsmallest(3, 'tweet_count')['author_name'].tolist()
    return bottom_3_authors
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    tweet_count = df.groupby('author_name').size().reset_index(name='tweet_count')
    bottom_3_authors = tweet_count.nsmallest(3, 'tweet_count')['author_name'].tolist()
    return bottom_3_authors
```
Response: ['Donald J. Trump']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    top_5_tweets = df.sort_values(by='retweets', ascending=False).head(5)['id'].tolist()
    return top_5_tweets
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    top_5_tweets = df.sort_values(by='retweets', ascending=False).head(5)['id'].tolist()
    return top_5_tweets
```
Response: [881503147168071680, 795954831718498305, 929511061954297857, 796315640307060738, 948355557022420992]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    bottom_4_tweets = df.nsmallest(4, 'favorites')['id'].tolist()
    return bottom_4_tweets
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    bottom_4_tweets = df.nsmallest(4, 'favorites')['id'].tolist()
    return bottom_4_tweets
```
Response: [591222909626114050, 591412084895838208, 586751374286721024, 575589231160127489]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    top_6_favorites = df['favorites'].nlargest(6).tolist()
    return top_6_favorites
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    top_6_favorites = df['favorites'].nlargest(6).tolist()
    return top_6_favorites
```
Response: [589793, 589750, 557779, 539249, 476457, 376626]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].nsmallest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'author_id', 'author_name', 'author_handler', 'author_avatar', 'lang', 'text', 'date','mention_ids','mention_names','retweets', 'favorites', 'links', 'links_first', 'image_links', 'image_links_first', 'tweet_link', 'rp_user_id', 'rp_user_name', 'location']
    return df['retweets'].nsmallest(3).tolist()
```
Response: [1, 1, 2]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['is_organization'].any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['is_organization'].any()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['is_organization'].eq(False).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['is_organization'].eq(False).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['pic'].notna().all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['pic'].notna().all()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].gt(500).any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].gt(500).any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['community'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['community'].nunique()
```
Response: 9
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['page_rank_norm'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['page_rank_norm'].mean()
```
Response: 0.08848033260794515
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].max()
```
Response: 770.5
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return len(df[df['community'] == 16744206])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return len(df[df['community'] == 16744206])
```
Response: 651
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['name'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['name'].mode()[0]
```
Response: David McCandless
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.loc[df['page_rank_norm'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.loc[df['page_rank_norm'].idxmax(), 'name']
```
Response: Mike Bostock
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    max_weight_entity = df.loc[df['weight'].idxmax()]
    return max_weight_entity['pic']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    max_weight_entity = df.loc[df['weight'].idxmax()]
    return max_weight_entity['pic']
```
Response: https://storage.googleapis.com/pics.contexto.io/photos/paperclips/000/016/457/thumb/Saw-whet_Owl_10_normal.jpg?1517502050
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.loc[df['y'].idxmax(), 'name']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.loc[df['y'].idxmax(), 'name']
```
Response: The Gibson Project
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    top_entities = df.sort_values(by='weight', ascending=False).head(3)['name'].tolist()
    return top_entities
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    top_entities = df.sort_values(by='weight', ascending=False).head(3)['name'].tolist()
    return top_entities
```
Response: ['Lynn Cherny', 'Alberto Cairo', 'Sinan Aral']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.nsmallest(2, 'page_rank_norm')['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.nsmallest(2, 'page_rank_norm')['name'].tolist()
```
Response: ['LIFE', 'New Options Project']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='x', ascending=False).head(4)['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='x', ascending=False).head(4)['name'].tolist()
```
Response: ['Detective.io', 'The Thrust', 'Open Budgets', 'NewsFuturist']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    # The columns used in the solution : ['y']
    return df.sort_values(by='y').head(3)['name'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='y').head(3)['name'].tolist()
```
Response: ['digital PR cat', 'Ismail Onur Filiz', 'Dave Golland']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='weight', ascending=False).head(5)['id'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='weight', ascending=False).head(5)['id'].tolist()
```
Response: [568, 423, 6392, 4548, 579]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='page_rank_norm').head(4)['id'].tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df.sort_values(by='page_rank_norm').head(4)['id'].tolist()
```
Response: [294, 63602, 35056, 35010]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should'] # Retain original column names 
    # The columns used in the solution : ['page_rank_norm']
    # The unique values of the columns used in the solution : 
    return df['page_rank_norm'].nlargest(6).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    # Retain original column names 
    # The columns used in the solution : ['page_rank_norm']
    return df['page_rank_norm'].nlargest(6).tolist()
```
Response: [1.0, 0.6029751067034804, 0.5666707687637932, 0.5202348027491394, 0.5110606617858531, 0.5081183103684572]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].nsmallest(3).tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['id', 'name', 'pic', 'is_organization', 'community', 'page_rank_norm', 'weight', 'x', 'y', 'twitter_profile_id', 'gx_link_target', 'gx_link_weight', 'gx_link_reciprocal', 'gx_link_should']
    return df['weight'].nsmallest(3).tolist()
```
Response: [1.0, 1.0, 1.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['feathers'].any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['feathers'].any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['venomous'].any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['venomous'].any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['breathes'].all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['breathes'].all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['domestic'].any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['domestic'].any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['animal_name'].nunique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['animal_name'].nunique()
```
Response: 100
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].mean()
```
Response: 2.8415841584158414
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].max()
```
Response: 8
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return len(df[df['legs'] == 2])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return len(df[df['legs'] == 2])
```
Response: 27
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['class_type'].mode()[0]
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['class_type'].mode()[0]
```
Response: 1
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    result = df[df['legs'] == 8].iloc[0]['animal_name']
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    result = df[df['legs'] == 8].iloc[0]['animal_name']
    return result
```
Response: octopus
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    max_legs = df['legs'].max()
    class_type_with_max_legs = df[df['legs'] == max_legs]['class_type'].iloc[0]
    return class_type_with_max_legs
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    max_legs = df['legs'].max()
    class_type_with_max_legs = df[df['legs'] == max_legs]['class_type'].iloc[0]
    return class_type_with_max_legs
```
Response: 7
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    # The columns used in the solution : ['animal_name','venomous']
    # The unique values of the columns used in the solution : 
    venomous_animals = df[df['venomous'] == 1]
    return venomous_animals['animal_name'].iloc[0] if not venomous_animals.empty else None
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    venomous_animals = df[df['venomous'] == 1]
    return venomous_animals['animal_name'].iloc[0] if not venomous_animals.empty else None
```
Response: frog
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    # The columns used in the solution : ['animal_name', 'legs']
    # The unique values of the columns used in the solution : 
    sorted_df = df.sort_values(by=['legs', 'animal_name'], ascending=[False, True])
    top_3_animals = sorted_df['animal_name'].head(3).tolist()
    return top_3_animals
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    sorted_df = df.sort_values(by=['legs', 'animal_name'], ascending=[False, True])
    top_3_animals = sorted_df['animal_name'].head(3).tolist()
    return top_3_animals
```
Response: ['octopus', 'scorpion', 'crayfish']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    bottom_two = df.sort_values(by=['legs', 'animal_name']).head(2)['animal_name'].tolist()
    return bottom_two
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    bottom_two = df.sort_values(by=['legs', 'animal_name']).head(2)['animal_name'].tolist()
    return bottom_two
```
Response: ['bass', 'carp']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    # The columns used in the solution : ['class_type']
    # The unique values of the columns used in the solution : 
    return df['class_type'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['class_type'].value_counts().head(4).index.tolist()
```
Response: [1, 2, 4, 7]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    class_counts = df['class_type'].value_counts().sort_values(ascending=True)
    return class_counts.head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    class_counts = df['class_type'].value_counts().sort_values(ascending=True)
    return class_counts.head(3).index.tolist()
```
Response: [5, 3, 6]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type'] # Retain original column names 
    result = df.groupby('class_type')['legs'].sum().nlargest(5).index.tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> None:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']  # Retain original column names 
    result = df.groupby('class_type')['legs'].sum().nlargest(5).index.tolist()
    return result
```
Response: [1, 6, 2, 7, 5]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    result = df.groupby('class_type')['legs'].sum().nsmallest(4).index.tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    result = df.groupby('class_type')['legs'].sum().nsmallest(4).index.tolist()
    return result
```
Response: [4, 3, 5, 7]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    return df['legs'].value_counts().head(4).index.tolist()
```
Response: [4, 2, 0, 6]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    leg_counts = df['legs'].value_counts().sort_values()
    return leg_counts.head(3).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['animal_name', 'hair', 'feathers', 'eggs','milk', 'airborne', 'aquatic', 'predator', 'toothed', 'backbone', 'breathes','venomous', 'fins', 'legs', 'tail', 'domestic', 'catsize', 'class_type']
    leg_counts = df['legs'].value_counts().sort_values()
    return leg_counts.head(3).index.tolist()
```
Response: [5, 8, 6]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return (df['Quantity'] > 0).all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return (df['Quantity'] > 0).all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return (df['UnitPrice'] > 0).all()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return (df['UnitPrice'] > 0).all()
```
Response: False
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['CustomerID'].isnull().any()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['CustomerID'].isnull().any()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return 'United Kingdom' in df['Country'].unique()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> bool:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return 'United Kingdom' in df['Country'].unique()
```
Response: True
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return len(df['StockCode'].unique())
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return len(df['StockCode'].unique())
```
Response: 4070
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> float:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['UnitPrice'].mean()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['UnitPrice'].mean()
```
Response: 4.611113626088513
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['Quantity'].max()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> float:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['Quantity'].max()
```
Response: 80995
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> int:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return len(df[df['Country'] == 'United Kingdom'])
```python
import pandas as pd

def answer(df: pd.DataFrame) -> int:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return len(df[df['Country'] == 'United Kingdom'])
```
Response: 495478
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_transactions = df['Country'].value_counts()
    return country_transactions.idxmax()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_transactions = df['Country'].value_counts()
    return country_transactions.idxmax()
```
Response: United Kingdom
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    # The columns used in the solution : ['Description', 'UnitPrice']
    # The unique values of the columns used in the solution : 
    return df.loc[df['UnitPrice'].idxmax(), 'Description']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df.loc[df['UnitPrice'].idxmax(), 'Description']
```
Response: Manual
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    max_quantity_description = df.loc[df['Quantity'].idxmax(), 'Description']
    return max_quantity_description
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    max_quantity_description = df.loc[df['Quantity'].idxmax(), 'Description']
    return max_quantity_description
```
Response: PAPER CRAFT , LITTLE BIRDIE
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    # The columns used in the solution : ['CustomerID', 'Country']
    # The unique values of the columns used in the solution : 
    return df.loc[df['CustomerID'].idxmin(), 'Country']
```python
import pandas as pd

def answer(df: pd.DataFrame) -> str:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df.loc[df['CustomerID'].idxmin(), 'Country']
```
Response: United Kingdom
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    top_items = df.groupby('Description')['Quantity'].sum().nlargest(3).index.tolist()
    return top_items
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    top_items = df.groupby('Description')['Quantity'].sum().nlargest(3).index.tolist()
    return top_items
```
Response: ['WORLD WAR 2 GLIDERS ASSTD DESIGNS', 'JUMBO BAG RED RETROSPOT', 'ASSORTED COLOUR BIRD ORNAMENT']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    result = df.sort_values(by=['Quantity', 'Description'], ascending=[True, True]).head(2)['Description'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    result = df.sort_values(by=['Quantity', 'Description'], ascending=[True, True]).head(2)['Description'].tolist()
    return result
```
Response: ['PAPER CRAFT , LITTLE BIRDIE', 'MEDIUM CERAMIC TOP STORAGE JAR']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_counts = df['Country'].value_counts().head(2)
    return country_counts.index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_counts = df['Country'].value_counts().head(2)
    return country_counts.index.tolist()
```
Response: ['United Kingdom', 'Germany']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_counts = df['Country'].value_counts().tail(2).index.tolist()
    return country_counts
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    country_counts = df['Country'].value_counts().tail(2).index.tolist()
    return country_counts
```
Response: ['Bahrain', 'Saudi Arabia']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    top_invoices = df.sort_values(by='Quantity', ascending=False).head(5)['InvoiceNo'].tolist()
    return top_invoices
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    top_invoices = df.sort_values(by='Quantity', ascending=False).head(5)['InvoiceNo'].tolist()
    return top_invoices
```
Response: [581483.0, 541431.0, 578841.0, 542504.0, 573008.0]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    # The columns used in the solution : ['StockCode', 'Quantity']
    # The unique values of the columns used in the solution : 
    result = df.sort_values(by=['Quantity', 'StockCode']).head(5)['StockCode'].tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    result = df.sort_values(by=['Quantity', 'StockCode']).head(5)['StockCode'].tolist()
    return result
```
Response: ['23843', '23166', '23005', '23005', '84347']
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    # The columns used in the solution : ['Quantity']
    # The unique values of the columns used in the solution : 
    return df['Quantity'].value_counts().head(4).index.tolist()
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    return df['Quantity'].value_counts().head(4).index.tolist()
```
Response: [1, 2, 12, 6]
--------------------
import pandas as pd
def answer(df: pd.DataFrame) -> None:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    # The columns used in the solution : ['Description', 'InvoiceDate']
    # The unique values of the columns used in the solution : 
    common_descriptions = df['Description'].value_counts().head(2).index
    result = df[df['Description'].isin(common_descriptions)][['Description', 'InvoiceDate']].values.tolist()
    return result
```python
import pandas as pd

def answer(df: pd.DataFrame) -> list:
    df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']
    common_descriptions = df['Description'].value_counts().head(2).index
    result = df[df['Description'].isin(common_descriptions)][['Description', 'InvoiceDate']].values.tolist()
    return result
```
Response: [['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 8:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 9:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 9:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 10:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 11:33'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 12:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 12:36'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 12:43'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 12:54'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 13:17'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 13:21'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 13:51'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 14:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 14:11'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 14:32'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 15:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 16:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 16:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 16:52'], ['REGENCY CAKESTAND 3 TIER', '12/1/2010 17:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 17:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2010 17:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 8:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 8:34'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 9:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 9:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 9:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 9:44'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 10:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 10:56'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 12:09'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 12:25'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 12:33'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 12:47'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 14:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 14:42'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 15:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 15:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 15:40'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 16:34'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 16:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 17:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 17:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2010 18:15'], ['REGENCY CAKESTAND 3 TIER', '12/2/2010 19:59'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 10:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 10:43'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 11:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 11:19'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 11:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 11:36'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 12:29'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 12:43'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 13:12'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 14:18'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 14:26'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 14:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 14:27'], ['REGENCY CAKESTAND 3 TIER', '12/3/2010 14:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/3/2010 15:19'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 10:12'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 10:27'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 11:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 11:12'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 11:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 11:45'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 11:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 12:13'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 12:44'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 13:00'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 14:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 15:15'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 15:47'], ['REGENCY CAKESTAND 3 TIER', '12/5/2010 16:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2010 16:24'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 9:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 9:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 10:05'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 11:38'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 11:42'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 12:06'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 12:38'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 12:55'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 13:06'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 13:22'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 13:35'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 13:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 14:05'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 14:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 14:36'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 14:36'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 15:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 15:14'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 15:35'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 16:57'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 16:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2010 16:57'], ['REGENCY CAKESTAND 3 TIER', '12/6/2010 17:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 9:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 9:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 10:04'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 11:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 11:45'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 12:45'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 12:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:01'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:18'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:28'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 13:53'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 15:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 15:28'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 15:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 15:31'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 15:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 15:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 16:20'], ['REGENCY CAKESTAND 3 TIER', '12/7/2010 18:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2010 18:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 8:58'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 9:20'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 9:51'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 10:35'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 10:40'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 11:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 11:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 12:36'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 13:03'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 13:07'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 13:11'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 13:21'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 13:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 14:25'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 14:25'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 14:43'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 14:46'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 14:50'], ['REGENCY CAKESTAND 3 TIER', '12/8/2010 15:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 16:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2010 16:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 8:34'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 9:30'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 10:00'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 10:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 10:42'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 10:48'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 11:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 12:13'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 13:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 13:57'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 14:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 14:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 14:55'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 16:08'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 16:08'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 16:26'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 16:27'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 16:31'], ['REGENCY CAKESTAND 3 TIER', '12/9/2010 16:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 16:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/9/2010 18:09'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 9:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 9:48'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 9:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 9:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 10:47'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 11:01'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 12:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 12:29'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 12:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 13:06'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 13:48'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 14:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 14:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 15:01'], ['REGENCY CAKESTAND 3 TIER', '12/10/2010 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/10/2010 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 11:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 11:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 11:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 11:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 12:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 12:24'], ['REGENCY CAKESTAND 3 TIER', '12/12/2010 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 12:44'], ['REGENCY CAKESTAND 3 TIER', '12/12/2010 12:46'], ['REGENCY CAKESTAND 3 TIER', '12/12/2010 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 13:32'], ['REGENCY CAKESTAND 3 TIER', '12/12/2010 13:32'], ['REGENCY CAKESTAND 3 TIER', '12/12/2010 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 14:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/12/2010 16:14'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 9:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 9:35'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 9:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 10:24'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 10:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 10:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 10:31'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 12:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 13:28'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 13:32'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 13:50'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 14:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 14:36'], ['REGENCY CAKESTAND 3 TIER', '12/13/2010 15:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 15:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 16:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/13/2010 17:40'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 9:50'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 9:54'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 10:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 11:26'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 11:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 11:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 13:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 13:33'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 14:11'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 15:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/14/2010 15:29'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 15:43'], ['REGENCY CAKESTAND 3 TIER', '12/14/2010 17:22'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 10:17'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 11:14'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 11:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 11:26'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 11:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 11:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 12:05'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 12:06'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 12:08'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 12:09'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 13:00'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/15/2010 14:29'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 14:35'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 16:50'], ['REGENCY CAKESTAND 3 TIER', '12/15/2010 17:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 8:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 9:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 9:46'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 10:08'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 10:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 11:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 12:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 12:20'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 12:20'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 12:42'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 13:21'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 14:19'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 14:36'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 15:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 15:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 16:36'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 16:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 18:20'], ['REGENCY CAKESTAND 3 TIER', '12/16/2010 18:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 19:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 19:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 19:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 19:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/16/2010 19:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 8:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 9:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 11:30'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 11:43'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 11:51'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 11:52'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 12:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 13:45'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 14:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 14:41'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 14:41'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 14:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 14:49'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 15:14'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 15:39'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 15:52'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 15:52'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 15:57'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 16:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 16:59'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 16:59'], ['REGENCY CAKESTAND 3 TIER', '12/17/2010 17:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 17:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/17/2010 17:12'], ['REGENCY CAKESTAND 3 TIER', '12/19/2010 11:38'], ['REGENCY CAKESTAND 3 TIER', '12/19/2010 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/19/2010 14:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/19/2010 14:16'], ['REGENCY CAKESTAND 3 TIER', '12/19/2010 14:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/19/2010 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/19/2010 15:44'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 10:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 11:08'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 11:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 12:51'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 12:51'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 13:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 13:21'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/20/2010 13:43'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 13:43'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 13:54'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 14:15'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 14:15'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 14:59'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 15:03'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 15:14'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 15:52'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 16:08'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 16:50'], ['REGENCY CAKESTAND 3 TIER', '12/20/2010 16:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 9:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 12:18'], ['REGENCY CAKESTAND 3 TIER', '12/21/2010 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 13:45'], ['REGENCY CAKESTAND 3 TIER', '12/21/2010 13:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 14:54'], ['REGENCY CAKESTAND 3 TIER', '12/21/2010 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/21/2010 15:40'], ['REGENCY CAKESTAND 3 TIER', '12/21/2010 15:43'], ['REGENCY CAKESTAND 3 TIER', '12/21/2010 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/22/2010 12:39'], ['REGENCY CAKESTAND 3 TIER', '12/22/2010 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/22/2010 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/22/2010 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/22/2010 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/22/2010 14:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/23/2010 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/23/2010 11:06'], ['REGENCY CAKESTAND 3 TIER', '12/23/2010 12:13'], ['REGENCY CAKESTAND 3 TIER', '12/23/2010 12:58'], ['REGENCY CAKESTAND 3 TIER', '12/23/2010 13:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/23/2010 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/23/2010 16:06'], ['REGENCY CAKESTAND 3 TIER', '12/23/2010 16:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 11:42'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 12:57'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 14:21'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 15:40'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 15:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/4/2011 15:50'], ['REGENCY CAKESTAND 3 TIER', '1/4/2011 16:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 10:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 11:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 13:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 13:40'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 13:57'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 15:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 15:40'], ['REGENCY CAKESTAND 3 TIER', '1/5/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/5/2011 17:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 9:00'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 9:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 11:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 12:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 12:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 15:11'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 16:03'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 16:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 16:35'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 16:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/6/2011 16:41'], ['REGENCY CAKESTAND 3 TIER', '1/6/2011 18:33'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 9:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 9:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 9:55'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 10:47'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 14:04'], ['REGENCY CAKESTAND 3 TIER', '1/7/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 14:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/7/2011 16:32'], ['REGENCY CAKESTAND 3 TIER', '1/9/2011 10:06'], ['REGENCY CAKESTAND 3 TIER', '1/9/2011 10:21'], ['REGENCY CAKESTAND 3 TIER', '1/9/2011 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 11:02'], ['REGENCY CAKESTAND 3 TIER', '1/9/2011 11:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 14:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 14:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 14:42'], ['REGENCY CAKESTAND 3 TIER', '1/9/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/9/2011 15:18'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 9:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/10/2011 9:44'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 12:03'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 14:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/10/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 15:16'], ['REGENCY CAKESTAND 3 TIER', '1/10/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 8:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 9:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 9:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 10:04'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 11:15'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 12:20'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 12:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 14:00'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 14:42'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 14:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/11/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '1/11/2011 15:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 9:26'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 11:18'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 12:43'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 13:40'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/12/2011 16:51'], ['REGENCY CAKESTAND 3 TIER', '1/12/2011 16:57'], ['REGENCY CAKESTAND 3 TIER', '1/13/2011 9:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/13/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/13/2011 10:35'], ['REGENCY CAKESTAND 3 TIER', '1/13/2011 11:26'], ['REGENCY CAKESTAND 3 TIER', '1/13/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/13/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '1/13/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/14/2011 10:20'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/14/2011 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/14/2011 12:27'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/14/2011 13:42'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 14:11'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 14:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/14/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '1/14/2011 16:55'], ['REGENCY CAKESTAND 3 TIER', '1/16/2011 10:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/16/2011 11:08'], ['REGENCY CAKESTAND 3 TIER', '1/16/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/16/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '1/16/2011 15:30'], ['REGENCY CAKESTAND 3 TIER', '1/16/2011 15:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/16/2011 15:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '1/17/2011 12:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 13:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 13:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '1/17/2011 14:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '1/17/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 16:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 17:54'], ['REGENCY CAKESTAND 3 TIER', '1/17/2011 17:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/17/2011 17:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/18/2011 8:53'], ['REGENCY CAKESTAND 3 TIER', '1/18/2011 9:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/18/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '1/18/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '1/18/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/18/2011 15:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/18/2011 16:31'], ['REGENCY CAKESTAND 3 TIER', '1/18/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/18/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/19/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/19/2011 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/19/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/19/2011 14:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/19/2011 16:19'], ['REGENCY CAKESTAND 3 TIER', '1/19/2011 17:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 12:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 14:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 14:01'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 15:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 15:00'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 16:15'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 18:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/20/2011 18:08'], ['REGENCY CAKESTAND 3 TIER', '1/20/2011 18:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/21/2011 11:17'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 11:55'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/21/2011 13:07'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/21/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/21/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 15:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/21/2011 15:56'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 17:04'], ['REGENCY CAKESTAND 3 TIER', '1/21/2011 17:09'], ['REGENCY CAKESTAND 3 TIER', '1/23/2011 10:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 10:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 12:08'], ['REGENCY CAKESTAND 3 TIER', '1/23/2011 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 13:34'], ['REGENCY CAKESTAND 3 TIER', '1/23/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '1/23/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/23/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/24/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 9:41'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 10:01'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 10:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/24/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 11:56'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/24/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '1/24/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/24/2011 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/24/2011 15:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 9:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 10:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 12:15'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 12:35'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:44'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 13:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 14:01'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 14:33'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/25/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '1/25/2011 16:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 8:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 12:27'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 12:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 13:40'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 15:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 16:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 17:08'], ['REGENCY CAKESTAND 3 TIER', '1/26/2011 17:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/26/2011 17:37'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 8:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 10:02'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 10:30'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 11:05'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 11:15'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 12:40'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 14:26'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 14:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 14:45'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/27/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '1/27/2011 18:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 9:18'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 9:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 11:27'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 12:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 12:43'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 13:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 13:08'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 14:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/28/2011 14:25'], ['REGENCY CAKESTAND 3 TIER', '1/28/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 12:09'], ['REGENCY CAKESTAND 3 TIER', '1/30/2011 12:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 12:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 14:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 14:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 14:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/30/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '1/30/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 9:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 9:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 9:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 9:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 9:50'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 10:31'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 11:27'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 11:46'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 12:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '1/31/2011 14:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '1/31/2011 14:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 8:31'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 9:01'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 9:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 9:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 11:20'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 13:55'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 15:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/1/2011 15:38'], ['REGENCY CAKESTAND 3 TIER', '2/1/2011 15:38'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 9:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 9:08'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 9:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 11:01'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 11:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 12:03'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 13:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 14:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 14:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 14:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 15:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 15:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/2/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '2/2/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 9:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 9:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 10:26'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 12:00'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 12:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 13:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 14:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '2/3/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/3/2011 19:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/4/2011 8:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/4/2011 9:34'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 10:38'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/4/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 12:18'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/4/2011 12:40'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/4/2011 14:51'], ['REGENCY CAKESTAND 3 TIER', '2/4/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/6/2011 11:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/6/2011 13:57'], ['REGENCY CAKESTAND 3 TIER', '2/6/2011 14:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/6/2011 16:08'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 9:15'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 9:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 11:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 11:42'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 12:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 13:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '2/7/2011 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 14:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/7/2011 14:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 10:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 10:47'], ['REGENCY CAKESTAND 3 TIER', '2/8/2011 11:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 11:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 11:36'], ['REGENCY CAKESTAND 3 TIER', '2/8/2011 12:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '2/8/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '2/8/2011 14:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/8/2011 15:09'], ['REGENCY CAKESTAND 3 TIER', '2/8/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '2/9/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/9/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '2/9/2011 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/9/2011 14:44'], ['REGENCY CAKESTAND 3 TIER', '2/9/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/9/2011 16:52'], ['REGENCY CAKESTAND 3 TIER', '2/9/2011 16:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/9/2011 16:57'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 10:18'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 10:40'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 11:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 13:34'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 14:51'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 15:40'], ['REGENCY CAKESTAND 3 TIER', '2/10/2011 16:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 16:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 17:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/10/2011 19:44'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 10:26'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 10:40'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 11:17'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 11:31'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 11:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 14:26'], ['REGENCY CAKESTAND 3 TIER', '2/11/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/11/2011 17:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/13/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/13/2011 12:05'], ['REGENCY CAKESTAND 3 TIER', '2/13/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '2/13/2011 15:02'], ['REGENCY CAKESTAND 3 TIER', '2/13/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '2/13/2011 15:45'], ['REGENCY CAKESTAND 3 TIER', '2/13/2011 16:05'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 9:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/14/2011 9:41'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 9:45'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 10:56'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 10:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/14/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 12:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/14/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '2/14/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 9:20'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 9:49'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 9:52'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/15/2011 12:48'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 15:46'], ['REGENCY CAKESTAND 3 TIER', '2/15/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '2/16/2011 9:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 9:56'], ['REGENCY CAKESTAND 3 TIER', '2/16/2011 10:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 10:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 10:47'], ['REGENCY CAKESTAND 3 TIER', '2/16/2011 10:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 12:11'], ['REGENCY CAKESTAND 3 TIER', '2/16/2011 12:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 13:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '2/16/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 14:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/16/2011 14:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 10:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 11:01'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 11:19'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 11:58'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 12:24'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 14:17'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 15:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/17/2011 15:50'], ['REGENCY CAKESTAND 3 TIER', '2/17/2011 19:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/18/2011 8:34'], ['REGENCY CAKESTAND 3 TIER', '2/18/2011 8:47'], ['REGENCY CAKESTAND 3 TIER', '2/18/2011 9:04'], ['REGENCY CAKESTAND 3 TIER', '2/18/2011 12:02'], ['REGENCY CAKESTAND 3 TIER', '2/18/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '2/18/2011 16:12'], ['REGENCY CAKESTAND 3 TIER', '2/20/2011 10:28'], ['REGENCY CAKESTAND 3 TIER', '2/20/2011 10:30'], ['REGENCY CAKESTAND 3 TIER', '2/20/2011 10:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/20/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '2/20/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '2/20/2011 14:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/20/2011 15:06'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 8:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/21/2011 8:33'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 10:32'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 11:46'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 12:54'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 13:40'], ['REGENCY CAKESTAND 3 TIER', '2/21/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/21/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/21/2011 17:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/21/2011 18:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/21/2011 18:15'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 9:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 13:08'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 13:47'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 13:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 13:59'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 14:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 15:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 15:09'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 15:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 15:14'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 15:22'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 16:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 16:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 16:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/22/2011 16:32'], ['REGENCY CAKESTAND 3 TIER', '2/22/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '2/23/2011 8:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 8:48'], ['REGENCY CAKESTAND 3 TIER', '2/23/2011 9:30'], ['REGENCY CAKESTAND 3 TIER', '2/23/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '2/23/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 12:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 13:37'], ['REGENCY CAKESTAND 3 TIER', '2/23/2011 14:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 15:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 16:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/23/2011 16:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 9:32'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 9:32'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 9:49'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 10:50'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 17:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 18:07'], ['REGENCY CAKESTAND 3 TIER', '2/24/2011 18:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/24/2011 18:59'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 9:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/25/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/25/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 13:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/25/2011 13:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/25/2011 14:11'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 14:24'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 15:37'], ['REGENCY CAKESTAND 3 TIER', '2/25/2011 17:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 10:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 11:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 11:48'], ['REGENCY CAKESTAND 3 TIER', '2/27/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '2/27/2011 13:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/27/2011 14:49'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 9:26'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 9:43'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 10:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 10:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 12:14'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 13:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 13:27'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 13:40'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 15:00'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 16:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '2/28/2011 16:47'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 16:47'], ['REGENCY CAKESTAND 3 TIER', '2/28/2011 16:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 10:26'], ['REGENCY CAKESTAND 3 TIER', '3/1/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 13:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 13:55'], ['REGENCY CAKESTAND 3 TIER', '3/1/2011 13:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 16:22'], ['REGENCY CAKESTAND 3 TIER', '3/1/2011 16:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/1/2011 16:22'], ['REGENCY CAKESTAND 3 TIER', '3/1/2011 16:22'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 8:26'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 8:41'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 9:03'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/2/2011 12:18'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/2/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 14:43'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/2/2011 14:50'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 16:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/2/2011 16:26'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 17:04'], ['REGENCY CAKESTAND 3 TIER', '3/2/2011 17:33'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 8:24'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 8:36'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 9:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 9:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 9:10'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 10:55'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 10:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 13:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 14:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 14:43'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 14:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 15:31'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 16:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 16:22'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 16:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 18:28'], ['REGENCY CAKESTAND 3 TIER', '3/3/2011 18:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/3/2011 19:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 10:03'], ['REGENCY CAKESTAND 3 TIER', '3/4/2011 12:06'], ['REGENCY CAKESTAND 3 TIER', '3/4/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 14:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 14:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/4/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '3/4/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '3/4/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '3/4/2011 16:07'], ['REGENCY CAKESTAND 3 TIER', '3/6/2011 10:07'], ['REGENCY CAKESTAND 3 TIER', '3/6/2011 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 12:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '3/6/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 14:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '3/6/2011 15:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/6/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 10:11'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 10:28'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 11:18'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 11:32'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/7/2011 12:00'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 12:26'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 13:10'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 13:37'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/7/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/7/2011 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/7/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/7/2011 17:14'], ['REGENCY CAKESTAND 3 TIER', '3/7/2011 17:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 8:53'], ['REGENCY CAKESTAND 3 TIER', '3/8/2011 10:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '3/8/2011 11:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 13:23'], ['REGENCY CAKESTAND 3 TIER', '3/8/2011 15:03'], ['REGENCY CAKESTAND 3 TIER', '3/8/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 16:48'], ['REGENCY CAKESTAND 3 TIER', '3/8/2011 17:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/8/2011 17:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 8:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 8:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 11:18'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 11:53'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 11:54'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 11:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 11:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 12:04'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 12:12'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 12:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 12:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 13:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 13:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/9/2011 13:56'], ['REGENCY CAKESTAND 3 TIER', '3/9/2011 14:49'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 10:03'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 11:17'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 12:59'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 14:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 14:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/10/2011 16:16'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 16:16'], ['REGENCY CAKESTAND 3 TIER', '3/10/2011 19:05'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 8:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/11/2011 9:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/11/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 11:18'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 11:35'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/11/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/11/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/11/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '3/11/2011 16:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/13/2011 12:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/13/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/14/2011 10:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/14/2011 11:04'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/14/2011 12:27'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 14:32'], ['REGENCY CAKESTAND 3 TIER', '3/14/2011 16:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/14/2011 16:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 9:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 9:22'], ['REGENCY CAKESTAND 3 TIER', '3/15/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 11:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '3/15/2011 13:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 13:49'], ['REGENCY CAKESTAND 3 TIER', '3/15/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/15/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '3/15/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '3/15/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 10:24'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 10:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 11:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 12:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 14:54'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/16/2011 16:08'], ['REGENCY CAKESTAND 3 TIER', '3/16/2011 16:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 9:49'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 9:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 10:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 12:37'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 12:40'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 13:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 15:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 15:47'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 17:16'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 18:08'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 18:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 18:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 18:18'], ['REGENCY CAKESTAND 3 TIER', '3/17/2011 18:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/17/2011 20:18'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 8:31'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 9:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 9:59'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 10:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 10:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 11:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 12:04'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 12:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 12:55'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 13:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/18/2011 13:47'], ['REGENCY CAKESTAND 3 TIER', '3/18/2011 14:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 10:13'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 10:17'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 11:00'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 11:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 12:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 12:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 13:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 14:23'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 15:02'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 15:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/20/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '3/20/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 9:13'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/21/2011 10:30'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 11:24'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 14:00'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '3/21/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/21/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 9:01'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 9:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 9:27'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 10:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 10:44'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 11:27'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 11:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 14:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 15:48'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 15:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/22/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '3/22/2011 16:54'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 8:54'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 8:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 9:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 10:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 12:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 12:39'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 14:04'], ['REGENCY CAKESTAND 3 TIER', '3/23/2011 15:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 15:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/23/2011 16:45'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 10:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 11:38'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 12:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 12:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 14:15'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 17:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/24/2011 18:43'], ['REGENCY CAKESTAND 3 TIER', '3/24/2011 19:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 8:41'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 10:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 10:14'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 11:01'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 12:00'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 12:04'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 12:48'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 12:57'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 15:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 15:50'], ['REGENCY CAKESTAND 3 TIER', '3/25/2011 17:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/25/2011 17:34'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 10:18'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 11:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 13:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 13:10'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 13:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 14:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 15:39'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 15:46'], ['REGENCY CAKESTAND 3 TIER', '3/27/2011 16:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/27/2011 16:08'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 7:53'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 8:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 9:21'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 10:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 15:10'], ['REGENCY CAKESTAND 3 TIER', '3/28/2011 15:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/28/2011 15:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 9:53'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 9:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 11:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 11:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 15:02'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 15:06'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/29/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '3/29/2011 17:23'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 9:12'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 9:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 9:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 9:31'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 11:04'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 11:18'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 12:12'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 12:15'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 13:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 15:06'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 15:14'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 16:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '3/30/2011 16:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/30/2011 17:33'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 9:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 9:48'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 9:57'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 10:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 11:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 12:43'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 13:10'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 13:49'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 14:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 16:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 16:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '3/31/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 16:41'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 17:12'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 17:16'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 17:17'], ['REGENCY CAKESTAND 3 TIER', '3/31/2011 19:54'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 8:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 8:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 9:06'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 10:11'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 10:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 11:28'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 12:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 13:47'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '4/1/2011 16:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/1/2011 16:49'], ['REGENCY CAKESTAND 3 TIER', '4/3/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 11:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 14:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/3/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 9:38'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 10:40'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 11:28'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 12:05'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 12:17'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 12:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 12:55'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 13:38'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 13:42'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 14:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 14:09'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 14:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 14:31'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 15:18'], ['REGENCY CAKESTAND 3 TIER', '4/4/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/4/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 10:18'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 11:42'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 11:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 12:08'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 12:08'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 12:30'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '4/5/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/5/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 11:07'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 11:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 12:49'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '4/6/2011 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/6/2011 17:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 9:12'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 10:09'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 10:10'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 10:13'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 10:20'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 10:43'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 11:40'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 13:24'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 19:05'], ['REGENCY CAKESTAND 3 TIER', '4/7/2011 19:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/7/2011 19:27'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 7:37'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 8:48'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 9:08'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 9:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/8/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/8/2011 10:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/8/2011 12:17'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 12:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/8/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/8/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '4/8/2011 14:14'], ['REGENCY CAKESTAND 3 TIER', '4/10/2011 10:10'], ['REGENCY CAKESTAND 3 TIER', '4/10/2011 11:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 12:22'], ['REGENCY CAKESTAND 3 TIER', '4/10/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 15:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 15:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 16:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/10/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 8:14'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 9:18'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 9:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 9:46'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 9:46'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 10:14'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 10:59'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 13:42'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 13:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 14:43'], ['REGENCY CAKESTAND 3 TIER', '4/11/2011 16:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 16:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/11/2011 17:12'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 9:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 10:30'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 10:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 10:58'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 14:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 15:08'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 16:19'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 16:21'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 16:39'], ['REGENCY CAKESTAND 3 TIER', '4/12/2011 16:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/12/2011 16:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 9:32'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 9:53'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 9:55'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 10:10'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 11:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 11:05'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 11:29'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 12:09'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 12:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 12:57'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 13:49'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 14:12'], ['REGENCY CAKESTAND 3 TIER', '4/13/2011 14:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/13/2011 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 8:32'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 8:32'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 8:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 8:49'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 9:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 9:28'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 9:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 10:17'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 12:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 12:42'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 13:17'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 17:29'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 17:58'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 18:22'], ['REGENCY CAKESTAND 3 TIER', '4/14/2011 18:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/14/2011 19:15'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 9:27'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/15/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 13:16'], ['REGENCY CAKESTAND 3 TIER', '4/15/2011 14:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/15/2011 16:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/17/2011 10:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/17/2011 10:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/17/2011 12:49'], ['REGENCY CAKESTAND 3 TIER', '4/17/2011 13:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/17/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '4/17/2011 14:05'], ['REGENCY CAKESTAND 3 TIER', '4/17/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 9:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 9:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 9:33'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 10:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 10:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 11:29'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 13:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:46'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 14:01'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 15:05'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '4/18/2011 15:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 16:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/18/2011 17:29'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 8:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 8:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 9:31'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 10:40'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 10:49'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 11:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 11:33'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 11:46'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 12:26'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 13:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 13:21'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 15:39'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 15:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/19/2011 15:44'], ['REGENCY CAKESTAND 3 TIER', '4/19/2011 16:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 8:07'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 10:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 10:48'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 11:48'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 14:02'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 14:46'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 15:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/20/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '4/20/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 8:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 10:19'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 10:55'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 12:07'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 14:21'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 14:21'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 15:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 16:17'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 16:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 16:37'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 16:37'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 16:48'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 16:59'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 17:31'], ['REGENCY CAKESTAND 3 TIER', '4/21/2011 18:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 18:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/21/2011 18:10'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 10:32'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 11:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 11:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 11:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 11:59'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 12:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 13:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 16:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 16:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 16:53'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 16:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 16:54'], ['REGENCY CAKESTAND 3 TIER', '4/26/2011 17:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/26/2011 17:02'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 8:17'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 12:02'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 14:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 14:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 14:16'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 14:16'], ['REGENCY CAKESTAND 3 TIER', '4/27/2011 14:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 14:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 17:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/27/2011 17:23'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 7:52'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 8:57'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 9:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 10:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 11:31'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 11:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 13:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 14:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 15:23'], ['REGENCY CAKESTAND 3 TIER', '4/28/2011 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '4/28/2011 16:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/1/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '5/1/2011 11:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/1/2011 11:36'], ['REGENCY CAKESTAND 3 TIER', '5/1/2011 13:45'], ['REGENCY CAKESTAND 3 TIER', '5/1/2011 14:17'], ['REGENCY CAKESTAND 3 TIER', '5/1/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 8:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 9:05'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 9:44'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 9:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 10:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 12:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 14:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '5/3/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/3/2011 16:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 9:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 11:12'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 11:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 11:32'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 14:03'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 14:11'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 15:08'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 15:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/4/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '5/4/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 8:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 8:33'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 9:11'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 9:13'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 9:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 10:31'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 11:08'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 11:38'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 11:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 12:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 13:19'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 13:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 13:56'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 13:56'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 14:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 14:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 15:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 15:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 15:47'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 16:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 17:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/5/2011 17:28'], ['REGENCY CAKESTAND 3 TIER', '5/5/2011 18:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 8:10'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 8:10'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 8:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 9:22'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 10:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 11:50'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 14:16'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 15:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 15:40'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 15:47'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/6/2011 16:01'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 16:01'], ['REGENCY CAKESTAND 3 TIER', '5/6/2011 16:17'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 10:43'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 11:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 12:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 14:06'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 15:22'], ['REGENCY CAKESTAND 3 TIER', '5/8/2011 16:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/8/2011 16:11'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 9:33'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 10:38'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 11:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 12:39'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 12:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 13:10'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 14:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 14:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 16:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/9/2011 16:37'], ['REGENCY CAKESTAND 3 TIER', '5/9/2011 16:59'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 9:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 11:04'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 12:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 13:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 13:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 13:24'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 14:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 15:09'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 15:25'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 15:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 16:00'], ['REGENCY CAKESTAND 3 TIER', '5/10/2011 16:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/10/2011 16:19'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 10:32'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 14:37'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 14:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 14:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 14:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/11/2011 14:54'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 15:34'], ['REGENCY CAKESTAND 3 TIER', '5/11/2011 16:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 8:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 9:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 9:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 9:59'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 10:13'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 10:23'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 10:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 12:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 13:58'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 16:29'], ['REGENCY CAKESTAND 3 TIER', '5/12/2011 18:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 18:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/12/2011 19:22'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 8:10'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/13/2011 10:44'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 11:53'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 13:52'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 15:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/13/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 15:48'], ['REGENCY CAKESTAND 3 TIER', '5/13/2011 15:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/13/2011 16:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/13/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 11:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 11:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 11:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 12:55'], ['REGENCY CAKESTAND 3 TIER', '5/15/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/15/2011 16:10'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 8:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 9:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 9:57'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 9:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 12:03'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 14:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 14:53'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 15:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '5/16/2011 16:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 16:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/16/2011 16:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 9:24'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 9:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 9:40'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 10:02'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 10:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 10:10'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 10:57'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 10:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 11:02'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 11:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 12:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 15:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 15:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/17/2011 16:09'], ['REGENCY CAKESTAND 3 TIER', '5/17/2011 16:23'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 9:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 11:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 12:15'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 13:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 13:11'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 14:50'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 15:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 16:14'], ['REGENCY CAKESTAND 3 TIER', '5/18/2011 16:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 16:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/18/2011 16:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 9:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 9:59'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 10:16'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 10:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 10:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 11:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 12:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 13:08'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 13:58'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 16:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 16:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 16:56'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 17:15'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 17:25'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 17:48'], ['REGENCY CAKESTAND 3 TIER', '5/19/2011 18:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/19/2011 19:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/20/2011 10:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/20/2011 10:37'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 10:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/20/2011 10:48'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 10:48'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/20/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 13:34'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 15:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/20/2011 15:29'], ['REGENCY CAKESTAND 3 TIER', '5/20/2011 16:25'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 11:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 11:51'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 14:03'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 14:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 15:03'], ['REGENCY CAKESTAND 3 TIER', '5/22/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/22/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 8:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 9:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 9:43'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 10:13'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 10:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 11:28'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 12:35'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 15:25'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 16:32'], ['REGENCY CAKESTAND 3 TIER', '5/23/2011 17:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/23/2011 17:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 8:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 9:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 10:42'], ['REGENCY CAKESTAND 3 TIER', '5/24/2011 10:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 11:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 11:35'], ['REGENCY CAKESTAND 3 TIER', '5/24/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '5/24/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 12:57'], ['REGENCY CAKESTAND 3 TIER', '5/24/2011 12:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 13:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 15:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/24/2011 15:58'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 10:08'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 10:12'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 11:12'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 11:26'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 12:39'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 16:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/25/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '5/25/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 10:09'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 10:44'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 11:02'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 11:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 12:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 13:21'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 13:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 14:20'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 18:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 18:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/26/2011 19:49'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 19:56'], ['REGENCY CAKESTAND 3 TIER', '5/26/2011 19:58'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 13:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/27/2011 13:32'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/27/2011 14:44'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 15:19'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 15:57'], ['REGENCY CAKESTAND 3 TIER', '5/27/2011 17:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 14:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 14:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '5/29/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/29/2011 15:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/31/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 9:37'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 10:24'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/31/2011 12:05'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 13:32'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 14:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/31/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 14:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/31/2011 14:34'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '5/31/2011 14:55'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '5/31/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 7:38'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 8:38'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 11:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 11:27'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 13:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 15:19'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 15:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 15:34'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 16:12'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 17:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 17:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 17:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/1/2011 17:30'], ['REGENCY CAKESTAND 3 TIER', '6/1/2011 17:33'], ['REGENCY CAKESTAND 3 TIER', '6/2/2011 9:37'], ['REGENCY CAKESTAND 3 TIER', '6/2/2011 11:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 11:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 17:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 17:26'], ['REGENCY CAKESTAND 3 TIER', '6/2/2011 17:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/2/2011 19:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/3/2011 10:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/3/2011 10:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/3/2011 11:42'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 12:17'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 12:26'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 15:31'], ['REGENCY CAKESTAND 3 TIER', '6/3/2011 15:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 10:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 10:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 11:29'], ['REGENCY CAKESTAND 3 TIER', '6/5/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 12:37'], ['REGENCY CAKESTAND 3 TIER', '6/5/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '6/5/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 14:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/5/2011 15:46'], ['REGENCY CAKESTAND 3 TIER', '6/5/2011 15:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 9:16'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 11:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 12:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 14:31'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/6/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 16:06'], ['REGENCY CAKESTAND 3 TIER', '6/6/2011 16:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/7/2011 10:46'], ['REGENCY CAKESTAND 3 TIER', '6/7/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '6/7/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/7/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '6/7/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/7/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/7/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '6/7/2011 16:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/7/2011 17:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 8:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 8:31'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 10:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 11:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 12:54'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 15:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 15:23'], ['REGENCY CAKESTAND 3 TIER', '6/8/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 17:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 17:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/8/2011 17:59'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/9/2011 13:16'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 13:37'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 13:46'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 15:34'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 16:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/9/2011 16:07'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 17:53'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 18:41'], ['REGENCY CAKESTAND 3 TIER', '6/9/2011 18:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/9/2011 19:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/9/2011 20:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 8:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 8:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 9:30'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 10:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 11:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 12:19'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 14:01'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 14:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 16:46'], ['REGENCY CAKESTAND 3 TIER', '6/10/2011 17:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/10/2011 17:25'], ['REGENCY CAKESTAND 3 TIER', '6/12/2011 11:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/12/2011 15:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/13/2011 8:44'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 8:44'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 10:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/13/2011 11:10'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 12:19'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 14:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/13/2011 15:09'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 15:25'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 15:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/13/2011 15:30'], ['REGENCY CAKESTAND 3 TIER', '6/13/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/14/2011 11:33'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/14/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/14/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/14/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 15:14'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 15:45'], ['REGENCY CAKESTAND 3 TIER', '6/14/2011 17:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/14/2011 17:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 8:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 10:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 10:24'], ['REGENCY CAKESTAND 3 TIER', '6/15/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '6/15/2011 11:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 11:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 11:56'], ['REGENCY CAKESTAND 3 TIER', '6/15/2011 12:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '6/15/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '6/15/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 14:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/15/2011 16:05'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 8:16'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 9:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/16/2011 9:46'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/16/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/16/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/16/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 16:31'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 16:43'], ['REGENCY CAKESTAND 3 TIER', '6/16/2011 19:59'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 8:09'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 10:43'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 11:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/17/2011 11:49'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/17/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/17/2011 13:01'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 14:09'], ['REGENCY CAKESTAND 3 TIER', '6/17/2011 15:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 10:11'], ['REGENCY CAKESTAND 3 TIER', '6/19/2011 11:26'], ['REGENCY CAKESTAND 3 TIER', '6/19/2011 11:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 12:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 13:56'], ['REGENCY CAKESTAND 3 TIER', '6/19/2011 13:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/19/2011 15:56'], ['REGENCY CAKESTAND 3 TIER', '6/20/2011 9:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/20/2011 10:34'], ['REGENCY CAKESTAND 3 TIER', '6/20/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '6/20/2011 15:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/20/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/21/2011 9:26'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 9:26'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 9:49'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 10:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/21/2011 10:48'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 10:55'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 13:24'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 14:00'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 14:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/21/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 16:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/21/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '6/21/2011 17:25'], ['REGENCY CAKESTAND 3 TIER', '6/22/2011 10:28'], ['REGENCY CAKESTAND 3 TIER', '6/22/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/22/2011 14:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/22/2011 14:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/22/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '6/22/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '6/22/2011 16:01'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 10:14'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 10:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 11:51'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 14:05'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '6/23/2011 16:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 17:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 18:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 18:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/23/2011 19:20'], ['REGENCY CAKESTAND 3 TIER', '6/24/2011 9:43'], ['REGENCY CAKESTAND 3 TIER', '6/24/2011 12:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/24/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/24/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/24/2011 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/24/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '6/24/2011 16:21'], ['REGENCY CAKESTAND 3 TIER', '6/24/2011 17:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/26/2011 10:59'], ['REGENCY CAKESTAND 3 TIER', '6/26/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '6/26/2011 14:06'], ['REGENCY CAKESTAND 3 TIER', '6/26/2011 14:08'], ['REGENCY CAKESTAND 3 TIER', '6/26/2011 15:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/27/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '6/27/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/27/2011 12:28'], ['REGENCY CAKESTAND 3 TIER', '6/27/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/27/2011 16:46'], ['REGENCY CAKESTAND 3 TIER', '6/27/2011 17:28'], ['REGENCY CAKESTAND 3 TIER', '6/28/2011 8:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/28/2011 10:17'], ['REGENCY CAKESTAND 3 TIER', '6/28/2011 13:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/28/2011 14:01'], ['REGENCY CAKESTAND 3 TIER', '6/28/2011 14:52'], ['REGENCY CAKESTAND 3 TIER', '6/28/2011 15:44'], ['REGENCY CAKESTAND 3 TIER', '6/29/2011 10:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '6/29/2011 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 10:50'], ['REGENCY CAKESTAND 3 TIER', '6/29/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 14:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 15:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 15:11'], ['REGENCY CAKESTAND 3 TIER', '6/29/2011 15:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 16:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/29/2011 16:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 8:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 10:09'], ['REGENCY CAKESTAND 3 TIER', '6/30/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 11:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 12:14'], ['REGENCY CAKESTAND 3 TIER', '6/30/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '6/30/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '6/30/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '7/1/2011 8:16'], ['REGENCY CAKESTAND 3 TIER', '7/1/2011 9:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/1/2011 10:47'], ['REGENCY CAKESTAND 3 TIER', '7/1/2011 12:09'], ['REGENCY CAKESTAND 3 TIER', '7/1/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/1/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/1/2011 13:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/1/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '7/1/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/1/2011 17:23'], ['REGENCY CAKESTAND 3 TIER', '7/3/2011 10:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/3/2011 11:40'], ['REGENCY CAKESTAND 3 TIER', '7/3/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/3/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '7/3/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/3/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '7/3/2011 15:19'], ['REGENCY CAKESTAND 3 TIER', '7/3/2011 15:53'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/4/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/4/2011 11:11'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/4/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/4/2011 12:28'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 14:08'], ['REGENCY CAKESTAND 3 TIER', '7/4/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/4/2011 16:06'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 9:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/5/2011 9:33'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 9:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/5/2011 10:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/5/2011 10:57'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 11:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/5/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 13:01'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 15:31'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 16:53'], ['REGENCY CAKESTAND 3 TIER', '7/5/2011 17:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/6/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '7/6/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '7/6/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '7/6/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/6/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 10:36'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 17:33'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 17:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 17:47'], ['REGENCY CAKESTAND 3 TIER', '7/7/2011 18:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 18:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 18:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/7/2011 19:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 9:03'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 10:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 13:53'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 14:53'], ['REGENCY CAKESTAND 3 TIER', '7/8/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/8/2011 15:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/10/2011 10:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/10/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/10/2011 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/10/2011 15:25'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 11:09'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/11/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/11/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/11/2011 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/11/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/11/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '7/11/2011 17:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 9:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 9:10'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 9:10'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 10:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 10:02'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 11:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 11:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 12:24'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 13:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 14:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 16:11'], ['REGENCY CAKESTAND 3 TIER', '7/12/2011 16:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/12/2011 17:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 10:09'], ['REGENCY CAKESTAND 3 TIER', '7/13/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '7/13/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 13:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 15:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/13/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '7/13/2011 16:07'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 9:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 9:22'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 9:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 9:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 10:15'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 10:20'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 10:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 12:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 13:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 13:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 14:08'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 14:46'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 15:02'], ['REGENCY CAKESTAND 3 TIER', '7/14/2011 16:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 18:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/14/2011 18:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/15/2011 8:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/15/2011 10:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/15/2011 10:44'], ['REGENCY CAKESTAND 3 TIER', '7/15/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '7/15/2011 14:05'], ['REGENCY CAKESTAND 3 TIER', '7/15/2011 15:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/15/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/15/2011 16:27'], ['REGENCY CAKESTAND 3 TIER', '7/15/2011 16:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 11:59'], ['REGENCY CAKESTAND 3 TIER', '7/17/2011 12:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 12:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '7/17/2011 12:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 13:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/17/2011 14:51'], ['REGENCY CAKESTAND 3 TIER', '7/17/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '7/18/2011 8:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 9:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 10:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '7/18/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 11:55'], ['REGENCY CAKESTAND 3 TIER', '7/18/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '7/18/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 14:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 14:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 15:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/18/2011 15:56'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 9:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 13:01'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 13:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 13:34'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 13:57'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 14:04'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 15:13'], ['REGENCY CAKESTAND 3 TIER', '7/19/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 16:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/19/2011 17:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 12:01'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 13:21'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 14:33'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 14:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 15:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 15:44'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 16:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 16:12'], ['REGENCY CAKESTAND 3 TIER', '7/20/2011 16:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/20/2011 16:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 9:31'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 10:32'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 11:42'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 12:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 17:12'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 17:39'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 17:55'], ['REGENCY CAKESTAND 3 TIER', '7/21/2011 18:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/21/2011 18:19'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 9:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 9:20'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 9:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 13:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 13:53'], ['REGENCY CAKESTAND 3 TIER', '7/22/2011 13:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/22/2011 16:03'], ['REGENCY CAKESTAND 3 TIER', '7/24/2011 10:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 10:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '7/24/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 12:20'], ['REGENCY CAKESTAND 3 TIER', '7/24/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 12:26'], ['REGENCY CAKESTAND 3 TIER', '7/24/2011 13:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/24/2011 14:33'], ['REGENCY CAKESTAND 3 TIER', '7/24/2011 15:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 10:01'], ['REGENCY CAKESTAND 3 TIER', '7/25/2011 10:19'], ['REGENCY CAKESTAND 3 TIER', '7/25/2011 10:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 11:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '7/25/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 13:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 13:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 15:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 16:18'], ['REGENCY CAKESTAND 3 TIER', '7/25/2011 16:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 17:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/25/2011 17:09'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 9:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/26/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 10:27'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 13:57'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 15:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/26/2011 16:25'], ['REGENCY CAKESTAND 3 TIER', '7/26/2011 17:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '7/27/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 14:14'], ['REGENCY CAKESTAND 3 TIER', '7/27/2011 14:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 15:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/27/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 9:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/28/2011 9:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/28/2011 11:29'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 12:19'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 13:02'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 13:05'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 14:33'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/28/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 15:58'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/28/2011 16:11'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 17:09'], ['REGENCY CAKESTAND 3 TIER', '7/28/2011 19:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 8:29'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 9:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 9:57'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 10:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 10:06'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 10:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 10:58'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 11:49'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 15:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '7/29/2011 16:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/29/2011 16:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 11:38'], ['REGENCY CAKESTAND 3 TIER', '7/31/2011 11:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 12:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 13:36'], ['REGENCY CAKESTAND 3 TIER', '7/31/2011 15:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 15:00'], ['REGENCY CAKESTAND 3 TIER', '7/31/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '7/31/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 11:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '8/1/2011 12:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '8/1/2011 14:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 14:16'], ['REGENCY CAKESTAND 3 TIER', '8/1/2011 16:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/1/2011 16:07'], ['REGENCY CAKESTAND 3 TIER', '8/1/2011 17:37'], ['REGENCY CAKESTAND 3 TIER', '8/2/2011 8:48'], ['REGENCY CAKESTAND 3 TIER', '8/2/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '8/2/2011 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/2/2011 12:59'], ['REGENCY CAKESTAND 3 TIER', '8/2/2011 14:00'], ['REGENCY CAKESTAND 3 TIER', '8/2/2011 14:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/2/2011 17:23'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 8:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 9:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 10:56'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 11:44'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 11:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 12:12'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 12:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 13:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 14:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 14:14'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '8/3/2011 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/3/2011 15:45'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 9:55'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 10:23'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 10:36'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 12:13'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 16:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 16:17'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 16:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 16:38'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 17:07'], ['REGENCY CAKESTAND 3 TIER', '8/4/2011 17:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/4/2011 18:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 13:52'], ['REGENCY CAKESTAND 3 TIER', '8/5/2011 13:52'], ['REGENCY CAKESTAND 3 TIER', '8/5/2011 14:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/5/2011 16:34'], ['REGENCY CAKESTAND 3 TIER', '8/5/2011 17:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '8/7/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 12:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 13:30'], ['REGENCY CAKESTAND 3 TIER', '8/7/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '8/7/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/7/2011 15:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 11:45'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 13:34'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 13:53'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 13:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 14:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 14:53'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '8/8/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/8/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '8/9/2011 10:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 10:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 11:56'], ['REGENCY CAKESTAND 3 TIER', '8/9/2011 12:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '8/9/2011 13:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 13:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '8/9/2011 14:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 15:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/9/2011 16:44'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 8:41'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 9:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/10/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 11:23'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 11:58'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 12:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/10/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 14:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/10/2011 16:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/10/2011 16:51'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 16:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/10/2011 17:11'], ['REGENCY CAKESTAND 3 TIER', '8/10/2011 17:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 10:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 10:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 10:55'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 12:17'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 12:58'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 14:54'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 16:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/11/2011 16:54'], ['REGENCY CAKESTAND 3 TIER', '8/11/2011 17:02'], ['REGENCY CAKESTAND 3 TIER', '8/12/2011 9:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/12/2011 10:13'], ['REGENCY CAKESTAND 3 TIER', '8/12/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '8/12/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/12/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/12/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/12/2011 14:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/14/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/14/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/14/2011 12:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/14/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 10:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 12:07'], ['REGENCY CAKESTAND 3 TIER', '8/15/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '8/15/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 14:32'], ['REGENCY CAKESTAND 3 TIER', '8/15/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '8/15/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/15/2011 15:06'], ['REGENCY CAKESTAND 3 TIER', '8/15/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/16/2011 10:44'], ['REGENCY CAKESTAND 3 TIER', '8/16/2011 10:48'], ['REGENCY CAKESTAND 3 TIER', '8/16/2011 10:50'], ['REGENCY CAKESTAND 3 TIER', '8/16/2011 11:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/16/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/16/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '8/16/2011 13:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/16/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/16/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '8/16/2011 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '8/17/2011 9:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '8/17/2011 11:37'], ['REGENCY CAKESTAND 3 TIER', '8/17/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '8/17/2011 13:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '8/17/2011 14:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/17/2011 14:47'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 6:24'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 8:49'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 8:51'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 10:23'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 13:01'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 14:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/18/2011 14:48'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 16:24'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 16:32'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 17:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/18/2011 17:43'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 18:21'], ['REGENCY CAKESTAND 3 TIER', '8/18/2011 19:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/18/2011 19:13'], ['REGENCY CAKESTAND 3 TIER', '8/19/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '8/19/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/19/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '8/19/2011 17:02'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 11:50'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 13:46'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/21/2011 14:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/21/2011 14:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/21/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/21/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '8/21/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 9:10'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 10:39'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/22/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/22/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 14:20'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/22/2011 14:38'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 15:55'], ['REGENCY CAKESTAND 3 TIER', '8/22/2011 17:10'], ['REGENCY CAKESTAND 3 TIER', '8/23/2011 9:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 9:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '8/23/2011 12:18'], ['REGENCY CAKESTAND 3 TIER', '8/23/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '8/23/2011 15:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 15:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 15:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 17:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/23/2011 17:31'], ['REGENCY CAKESTAND 3 TIER', '8/23/2011 17:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 9:36'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 10:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 10:37'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 11:31'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 11:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 11:54'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 11:54'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 12:23'], ['REGENCY CAKESTAND 3 TIER', '8/24/2011 13:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 13:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/24/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 9:39'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 9:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 10:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 10:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 10:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 12:57'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 13:46'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 14:15'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 14:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 15:04'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 15:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 15:10'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 15:10'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 15:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/25/2011 17:22'], ['REGENCY CAKESTAND 3 TIER', '8/25/2011 17:22'], ['REGENCY CAKESTAND 3 TIER', '8/26/2011 9:37'], ['REGENCY CAKESTAND 3 TIER', '8/26/2011 10:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/26/2011 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/26/2011 11:58'], ['REGENCY CAKESTAND 3 TIER', '8/26/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '8/26/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '8/26/2011 15:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 10:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 10:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 11:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 13:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 13:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 14:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/28/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 10:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 10:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 10:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 12:10'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 12:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 12:40'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 12:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 12:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 12:49'], ['REGENCY CAKESTAND 3 TIER', '8/30/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/30/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '8/31/2011 8:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/31/2011 9:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/31/2011 14:28'], ['REGENCY CAKESTAND 3 TIER', '8/31/2011 15:30'], ['REGENCY CAKESTAND 3 TIER', '8/31/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/31/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/31/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '8/31/2011 16:09'], ['REGENCY CAKESTAND 3 TIER', '8/31/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '8/31/2011 17:12'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 9:15'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 10:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 10:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 10:36'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 14:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 14:26'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 16:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 16:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/1/2011 16:50'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 17:20'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 17:45'], ['REGENCY CAKESTAND 3 TIER', '9/1/2011 19:08'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 9:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 9:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 9:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 9:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 9:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 9:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 10:20'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 11:31'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 15:16'], ['REGENCY CAKESTAND 3 TIER', '9/2/2011 15:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/2/2011 16:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/4/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/4/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/4/2011 13:56'], ['REGENCY CAKESTAND 3 TIER', '9/4/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '9/4/2011 15:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 9:07'], ['REGENCY CAKESTAND 3 TIER', '9/5/2011 9:45'], ['REGENCY CAKESTAND 3 TIER', '9/5/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 13:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 14:27'], ['REGENCY CAKESTAND 3 TIER', '9/5/2011 15:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 15:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/5/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 9:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 9:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 9:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 10:42'], ['REGENCY CAKESTAND 3 TIER', '9/6/2011 11:53'], ['REGENCY CAKESTAND 3 TIER', '9/6/2011 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 12:00'], ['REGENCY CAKESTAND 3 TIER', '9/6/2011 12:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '9/6/2011 14:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 14:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/6/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/7/2011 10:23'], ['REGENCY CAKESTAND 3 TIER', '9/7/2011 10:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/7/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/7/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '9/7/2011 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/7/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '9/7/2011 14:56'], ['REGENCY CAKESTAND 3 TIER', '9/8/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/8/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/8/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/8/2011 11:48'], ['REGENCY CAKESTAND 3 TIER', '9/8/2011 13:38'], ['REGENCY CAKESTAND 3 TIER', '9/8/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/8/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '9/8/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '9/8/2011 15:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/8/2011 15:27'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 11:15'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 11:56'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 12:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/9/2011 12:22'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '9/9/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/9/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/9/2011 14:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/9/2011 14:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 11:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 11:17'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 11:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 11:24'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 11:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 12:03'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 12:23'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 13:58'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 14:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 14:09'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 15:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/11/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '9/11/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 9:38'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 10:19'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 12:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 12:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 12:48'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 12:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 13:11'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 13:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 13:38'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 13:43'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 13:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 14:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 16:14'], ['REGENCY CAKESTAND 3 TIER', '9/12/2011 18:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/12/2011 18:18'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 9:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 9:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 9:43'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 10:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 10:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 11:24'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 11:32'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 11:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 12:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 13:21'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 13:29'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 13:47'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 13:55'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 14:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 15:37'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 15:37'], ['REGENCY CAKESTAND 3 TIER', '9/13/2011 15:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/13/2011 16:27'], ['REGENCY CAKESTAND 3 TIER', '9/14/2011 9:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/14/2011 9:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/14/2011 9:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/14/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/14/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '9/14/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/14/2011 12:42'], ['REGENCY CAKESTAND 3 TIER', '9/14/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 8:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 10:31'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 10:31'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 10:35'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 10:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 11:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 12:02'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 12:51'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 15:29'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 16:16'], ['REGENCY CAKESTAND 3 TIER', '9/15/2011 16:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/15/2011 16:37'], ['REGENCY CAKESTAND 3 TIER', '9/16/2011 9:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/16/2011 9:54'], ['REGENCY CAKESTAND 3 TIER', '9/16/2011 10:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/16/2011 10:42'], ['REGENCY CAKESTAND 3 TIER', '9/16/2011 10:56'], ['REGENCY CAKESTAND 3 TIER', '9/16/2011 11:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/16/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/16/2011 14:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/16/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '9/18/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/18/2011 13:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/18/2011 13:38'], ['REGENCY CAKESTAND 3 TIER', '9/18/2011 14:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/18/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '9/18/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/18/2011 15:55'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 10:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 11:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 11:04'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 11:46'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 12:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 13:27'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 13:48'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 14:52'], ['REGENCY CAKESTAND 3 TIER', '9/19/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 15:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/19/2011 16:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 10:01'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 10:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 10:38'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 12:30'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 12:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 12:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 13:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 13:11'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/20/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '9/20/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 8:55'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 14:38'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 14:50'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 15:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/21/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/21/2011 15:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/21/2011 15:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/21/2011 15:43'], ['REGENCY CAKESTAND 3 TIER', '9/21/2011 16:43'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 8:41'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 9:16'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 10:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 10:38'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 10:58'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 12:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 14:13'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 14:25'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 15:03'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 15:39'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 15:51'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 16:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/22/2011 17:07'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 17:15'], ['REGENCY CAKESTAND 3 TIER', '9/22/2011 18:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 9:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 9:26'], ['REGENCY CAKESTAND 3 TIER', '9/23/2011 11:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 12:16'], ['REGENCY CAKESTAND 3 TIER', '9/23/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 12:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 12:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '9/23/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 13:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 13:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 13:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 14:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 15:50'], ['REGENCY CAKESTAND 3 TIER', '9/23/2011 17:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/23/2011 17:04'], ['REGENCY CAKESTAND 3 TIER', '9/25/2011 11:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '9/25/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '9/25/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 13:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 14:32'], ['REGENCY CAKESTAND 3 TIER', '9/25/2011 14:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 14:52'], ['REGENCY CAKESTAND 3 TIER', '9/25/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/25/2011 15:56'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 9:52'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 12:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/26/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/26/2011 12:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/26/2011 12:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/26/2011 12:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/26/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 12:48'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 14:48'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 15:28'], ['REGENCY CAKESTAND 3 TIER', '9/26/2011 16:15'], ['REGENCY CAKESTAND 3 TIER', '9/27/2011 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/27/2011 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/27/2011 11:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/27/2011 12:52'], ['REGENCY CAKESTAND 3 TIER', '9/27/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/27/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/27/2011 17:47'], ['REGENCY CAKESTAND 3 TIER', '9/27/2011 18:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 11:26'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 12:46'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 13:13'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 13:30'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 13:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 14:56'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 15:42'], ['REGENCY CAKESTAND 3 TIER', '9/28/2011 16:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 16:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/28/2011 16:35'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 8:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 9:23'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 9:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 10:46'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 10:49'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 13:22'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 13:38'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/29/2011 15:13'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 15:13'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '9/29/2011 15:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 9:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '9/30/2011 10:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '9/30/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '9/30/2011 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 13:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 14:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 14:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 14:55'], ['REGENCY CAKESTAND 3 TIER', '9/30/2011 14:55'], ['REGENCY CAKESTAND 3 TIER', '9/30/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 15:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '9/30/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '10/2/2011 10:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '10/2/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '10/2/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 14:56'], ['REGENCY CAKESTAND 3 TIER', '10/2/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '10/2/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/2/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 8:30'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 9:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/3/2011 9:57'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/3/2011 10:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/3/2011 11:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/3/2011 13:03'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 15:28'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 15:28'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '10/3/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/3/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 8:26'], ['REGENCY CAKESTAND 3 TIER', '10/4/2011 9:12'], ['REGENCY CAKESTAND 3 TIER', '10/4/2011 10:11'], ['REGENCY CAKESTAND 3 TIER', '10/4/2011 10:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 12:22'], ['REGENCY CAKESTAND 3 TIER', '10/4/2011 13:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 14:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 14:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 16:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/4/2011 17:31'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 8:17'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 9:57'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 10:06'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 11:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 11:25'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 12:44'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 12:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 13:19'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 13:58'], ['REGENCY CAKESTAND 3 TIER', '10/5/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/5/2011 16:09'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 9:31'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 9:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/6/2011 9:36'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 12:22'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 15:51'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 16:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/6/2011 16:08'], ['REGENCY CAKESTAND 3 TIER', '10/6/2011 16:28'], ['REGENCY CAKESTAND 3 TIER', '10/7/2011 8:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 9:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 10:06'], ['REGENCY CAKESTAND 3 TIER', '10/7/2011 10:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 10:21'], ['REGENCY CAKESTAND 3 TIER', '10/7/2011 11:22'], ['REGENCY CAKESTAND 3 TIER', '10/7/2011 11:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 11:32'], ['REGENCY CAKESTAND 3 TIER', '10/7/2011 11:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 12:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 15:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/7/2011 16:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/9/2011 13:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/9/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '10/9/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/9/2011 16:05'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 8:23'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 9:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 9:56'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 12:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 12:19'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 12:26'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 14:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/10/2011 14:37'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '10/10/2011 16:55'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 8:23'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 10:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/11/2011 11:34'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 11:37'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 11:43'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 11:49'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 11:55'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 14:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/11/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 15:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/11/2011 15:10'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '10/11/2011 16:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/11/2011 16:29'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 9:29'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 9:29'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 10:04'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 10:18'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 12:19'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 13:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 15:01'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 16:36'], ['REGENCY CAKESTAND 3 TIER', '10/12/2011 16:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/12/2011 17:00'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 10:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 10:25'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 12:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 12:38'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:47'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:50'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:58'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 12:59'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 13:49'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 14:10'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 14:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 14:37'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 14:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 15:38'], ['REGENCY CAKESTAND 3 TIER', '10/13/2011 15:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 15:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/13/2011 16:24'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 9:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 9:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 13:06'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 13:06'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 13:35'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 14:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 14:04'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 14:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 15:26'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 17:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/14/2011 17:17'], ['REGENCY CAKESTAND 3 TIER', '10/14/2011 17:17'], ['REGENCY CAKESTAND 3 TIER', '10/16/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/16/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/16/2011 12:54'], ['REGENCY CAKESTAND 3 TIER', '10/16/2011 13:23'], ['REGENCY CAKESTAND 3 TIER', '10/16/2011 13:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/16/2011 13:51'], ['REGENCY CAKESTAND 3 TIER', '10/16/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/16/2011 14:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/16/2011 15:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 10:43'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 12:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 12:41'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 13:19'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 13:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 13:31'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 13:44'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 14:12'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 15:18'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 15:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 15:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/17/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '10/17/2011 17:24'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 9:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/18/2011 9:15'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 9:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/18/2011 10:07'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/18/2011 12:17'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 12:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/18/2011 14:49'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 16:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/18/2011 16:58'], ['REGENCY CAKESTAND 3 TIER', '10/18/2011 17:05'], ['REGENCY CAKESTAND 3 TIER', '10/19/2011 8:20'], ['REGENCY CAKESTAND 3 TIER', '10/19/2011 11:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '10/19/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 11:52'], ['REGENCY CAKESTAND 3 TIER', '10/19/2011 11:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 13:37'], ['REGENCY CAKESTAND 3 TIER', '10/19/2011 13:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/19/2011 16:59'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 11:40'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 12:03'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 12:53'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 13:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/20/2011 13:06'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 14:18'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/20/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '10/20/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '10/21/2011 9:20'], ['REGENCY CAKESTAND 3 TIER', '10/21/2011 10:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/21/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '10/21/2011 12:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/21/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/21/2011 13:17'], ['REGENCY CAKESTAND 3 TIER', '10/21/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/21/2011 15:18'], ['REGENCY CAKESTAND 3 TIER', '10/21/2011 16:48'], ['REGENCY CAKESTAND 3 TIER', '10/23/2011 9:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 11:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 12:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '10/23/2011 14:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 14:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 15:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 15:11'], ['REGENCY CAKESTAND 3 TIER', '10/23/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/23/2011 15:29'], ['REGENCY CAKESTAND 3 TIER', '10/23/2011 15:30'], ['REGENCY CAKESTAND 3 TIER', '10/23/2011 16:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/24/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/24/2011 12:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/24/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '10/24/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '10/24/2011 17:03'], ['REGENCY CAKESTAND 3 TIER', '10/24/2011 17:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/24/2011 17:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/24/2011 17:09'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 11:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/25/2011 13:10'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 14:39'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 15:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/25/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '10/25/2011 15:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/25/2011 16:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/25/2011 17:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/25/2011 18:39'], ['REGENCY CAKESTAND 3 TIER', '10/26/2011 10:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/26/2011 11:14'], ['REGENCY CAKESTAND 3 TIER', '10/26/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/26/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/26/2011 16:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/26/2011 16:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/26/2011 16:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 10:01'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 10:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 13:45'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 14:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 14:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 14:21'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 14:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 16:41'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 16:58'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 17:00'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 17:00'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 17:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 17:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/27/2011 18:02'], ['REGENCY CAKESTAND 3 TIER', '10/27/2011 18:02'], ['REGENCY CAKESTAND 3 TIER', '10/28/2011 9:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '10/28/2011 12:34'], ['REGENCY CAKESTAND 3 TIER', '10/28/2011 12:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 13:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 13:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 14:38'], ['REGENCY CAKESTAND 3 TIER', '10/28/2011 14:42'], ['REGENCY CAKESTAND 3 TIER', '10/28/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 16:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 16:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/28/2011 16:45'], ['REGENCY CAKESTAND 3 TIER', '10/30/2011 10:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '10/30/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '10/30/2011 11:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 11:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 11:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 12:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 14:21'], ['REGENCY CAKESTAND 3 TIER', '10/30/2011 15:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 15:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 15:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 15:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 15:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 15:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/30/2011 16:17'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 9:48'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 9:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 11:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 11:59'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 12:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 13:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 13:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 13:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 14:09'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 14:09'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 14:22'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 14:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 14:36'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 14:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 14:41'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 15:24'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 15:36'], ['REGENCY CAKESTAND 3 TIER', '10/31/2011 16:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 16:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '10/31/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 9:24'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 9:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 11:29'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 11:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 11:39'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 12:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 13:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 13:44'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 13:57'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 14:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 15:06'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 15:49'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 15:53'], ['REGENCY CAKESTAND 3 TIER', '11/1/2011 15:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/1/2011 17:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 11:49'], ['REGENCY CAKESTAND 3 TIER', '11/2/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 14:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '11/2/2011 14:57'], ['REGENCY CAKESTAND 3 TIER', '11/2/2011 15:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/2/2011 15:33'], ['REGENCY CAKESTAND 3 TIER', '11/2/2011 15:38'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 8:56'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 10:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 12:56'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 15:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 15:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 16:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/3/2011 16:56'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 19:15'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 19:28'], ['REGENCY CAKESTAND 3 TIER', '11/3/2011 19:42'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 9:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 9:05'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 9:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 10:10'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 11:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 12:21'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 13:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 14:03'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 14:03'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 14:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 14:26'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 14:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 15:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/4/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 15:52'], ['REGENCY CAKESTAND 3 TIER', '11/4/2011 18:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 11:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 11:55'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 12:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 12:31'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 13:36'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 14:02'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 14:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 14:45'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 14:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/6/2011 16:01'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 16:04'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 16:07'], ['REGENCY CAKESTAND 3 TIER', '11/6/2011 16:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 7:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 9:24'], ['REGENCY CAKESTAND 3 TIER', '11/7/2011 10:23'], ['REGENCY CAKESTAND 3 TIER', '11/7/2011 12:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 12:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 14:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 15:07'], ['REGENCY CAKESTAND 3 TIER', '11/7/2011 15:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/7/2011 17:15'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 9:29'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 9:44'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 9:56'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 11:09'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 11:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 12:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 12:09'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 12:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 13:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 13:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 13:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 14:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 15:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 15:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 15:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 15:48'], ['REGENCY CAKESTAND 3 TIER', '11/8/2011 16:15'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 16:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/8/2011 18:41'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 8:36'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 9:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 11:04'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 11:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 12:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 12:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/9/2011 13:45'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 16:14'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 17:02'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 17:03'], ['REGENCY CAKESTAND 3 TIER', '11/9/2011 17:47'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 10:29'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 10:41'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 10:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 12:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 12:29'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 12:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 14:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 14:16'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 15:23'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 16:51'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 16:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 18:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/10/2011 19:12'], ['REGENCY CAKESTAND 3 TIER', '11/10/2011 19:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 8:46'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 9:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 9:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 10:03'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 10:19'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 10:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 10:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 11:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 11:06'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 12:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 12:11'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 12:20'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 12:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 14:12'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 16:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 16:57'], ['REGENCY CAKESTAND 3 TIER', '11/11/2011 16:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 16:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/11/2011 17:23'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 10:35'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 11:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 11:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 12:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 12:27'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 12:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 13:26'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 13:27'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 13:42'], ['REGENCY CAKESTAND 3 TIER', '11/13/2011 14:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 14:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/13/2011 15:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 8:56'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 9:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 10:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 13:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 14:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 14:24'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 14:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 14:24'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 14:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 15:22'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 15:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 15:27'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 15:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 15:37'], ['REGENCY CAKESTAND 3 TIER', '11/14/2011 16:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/14/2011 17:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 8:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 8:50'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 10:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 10:51'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 12:33'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 12:57'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 13:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 14:29'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 14:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 14:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 15:08'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 16:42'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 16:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/15/2011 16:57'], ['REGENCY CAKESTAND 3 TIER', '11/15/2011 17:00'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 8:28'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 9:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 9:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 10:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 10:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 11:46'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 11:48'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 12:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 12:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 12:25'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 12:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 13:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 15:16'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 15:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 15:21'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 15:23'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 15:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 15:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/16/2011 16:06'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 16:06'], ['REGENCY CAKESTAND 3 TIER', '11/16/2011 16:09'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 8:40'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 8:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 9:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 10:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 10:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 11:54'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 12:32'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 13:16'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 13:30'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 14:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 14:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 14:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 14:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 15:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 15:17'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 15:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 15:47'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 15:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 17:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/17/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '11/17/2011 18:29'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 9:42'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 9:48'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 10:42'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 12:07'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 13:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 13:14'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 13:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 13:42'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 15:14'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 15:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 15:53'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/18/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 16:58'], ['REGENCY CAKESTAND 3 TIER', '11/18/2011 17:06'], ['REGENCY CAKESTAND 3 TIER', '11/20/2011 11:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 11:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 11:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 12:07'], ['REGENCY CAKESTAND 3 TIER', '11/20/2011 12:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 12:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 12:45'], ['REGENCY CAKESTAND 3 TIER', '11/20/2011 12:55'], ['REGENCY CAKESTAND 3 TIER', '11/20/2011 13:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '11/20/2011 13:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 13:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 13:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/20/2011 16:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 8:19'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 8:19'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 8:19'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 9:11'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 9:51'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 9:55'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 10:27'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 10:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 11:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 11:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '11/21/2011 12:19'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 15:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/21/2011 16:17'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 9:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 9:53'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 10:18'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 10:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 11:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 12:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 13:07'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 13:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 14:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 14:59'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 15:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 15:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 15:45'], ['REGENCY CAKESTAND 3 TIER', '11/22/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 16:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 16:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 16:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/22/2011 16:47'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 8:43'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 10:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 10:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 11:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 11:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 11:47'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 12:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 12:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 13:01'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 13:15'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 13:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 13:39'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 14:07'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 14:35'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 14:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/23/2011 15:41'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 15:44'], ['REGENCY CAKESTAND 3 TIER', '11/23/2011 16:22'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 8:44'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 9:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 9:21'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 9:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 9:26'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 9:59'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 10:12'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 10:35'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 10:40'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 10:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 12:11'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 12:12'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 12:36'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 12:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 13:06'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 13:32'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 14:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 15:01'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 15:32'], ['REGENCY CAKESTAND 3 TIER', '11/24/2011 15:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 16:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/24/2011 16:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 8:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 8:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 8:55'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 9:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 9:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 9:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 9:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 11:12'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 11:36'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 12:10'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 12:20'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 13:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 13:45'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 14:02'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 14:25'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/25/2011 16:14'], ['REGENCY CAKESTAND 3 TIER', '11/25/2011 16:14'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/27/2011 11:54'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 11:57'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 13:18'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 13:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/27/2011 13:41'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 14:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/27/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 14:30'], ['REGENCY CAKESTAND 3 TIER', '11/27/2011 15:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/27/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 9:43'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 10:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 10:54'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 11:33'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 12:45'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 13:20'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 13:27'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 14:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 15:16'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 15:31'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 15:31'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 15:35'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 15:43'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 15:47'], ['REGENCY CAKESTAND 3 TIER', '11/28/2011 15:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/28/2011 15:54'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 10:45'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 11:21'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 11:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 11:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 11:32'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 11:50'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 12:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 13:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 14:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 14:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 14:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 15:06'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 15:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 15:59'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 16:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 16:33'], ['REGENCY CAKESTAND 3 TIER', '11/29/2011 16:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/29/2011 16:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 8:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 8:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 9:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 10:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 10:54'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 11:08'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 11:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 11:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 11:30'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 11:49'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 12:15'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 12:18'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 12:41'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 13:50'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 14:09'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 14:11'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 14:40'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 14:46'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 14:46'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 15:13'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 16:47'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 17:12'], ['REGENCY CAKESTAND 3 TIER', '11/30/2011 17:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '11/30/2011 17:37'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 8:52'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 9:20'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 9:44'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 10:33'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 11:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 13:08'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 13:28'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 13:33'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 13:47'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 14:58'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 15:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 15:12'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 16:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 16:22'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 17:56'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 17:56'], ['REGENCY CAKESTAND 3 TIER', '12/1/2011 18:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 19:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/1/2011 19:54'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 10:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 10:52'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 11:43'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 12:36'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 13:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 13:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 13:37'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 13:54'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 14:25'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 14:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 15:29'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 16:07'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '12/2/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/2/2011 16:39'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/4/2011 10:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/4/2011 13:00'], ['REGENCY CAKESTAND 3 TIER', '12/4/2011 13:32'], ['REGENCY CAKESTAND 3 TIER', '12/4/2011 13:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/4/2011 13:59'], ['REGENCY CAKESTAND 3 TIER', '12/4/2011 14:51'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/4/2011 15:00'], ['REGENCY CAKESTAND 3 TIER', '12/4/2011 15:18'], ['REGENCY CAKESTAND 3 TIER', '12/4/2011 16:02'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 8:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 10:18'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 11:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 11:49'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 11:58'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 12:16'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 12:30'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 12:30'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 12:44'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 12:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 13:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 13:58'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 14:06'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 14:19'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 14:25'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 15:38'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 15:51'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 16:03'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 16:03'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 16:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 17:13'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 17:17'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 17:17'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 17:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 17:24'], ['REGENCY CAKESTAND 3 TIER', '12/5/2011 17:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/5/2011 17:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2011 9:35'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 10:00'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 10:05'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 10:05'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 11:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2011 11:23'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2011 11:41'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 12:06'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 12:15'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 12:56'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2011 13:13'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/6/2011 14:14'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 14:40'], ['REGENCY CAKESTAND 3 TIER', '12/6/2011 14:52'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 8:45'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 9:02'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 9:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 10:12'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 10:24'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 10:35'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 11:12'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 11:42'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 12:48'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 12:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 13:21'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 13:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 14:12'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 14:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 15:08'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 15:16'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 15:43'], ['REGENCY CAKESTAND 3 TIER', '12/7/2011 17:05'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/7/2011 17:05'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 9:20'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 9:20'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 9:28'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 9:28'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 10:06'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 10:33'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 10:34'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 10:53'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 10:59'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 11:15'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 11:21'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 11:21'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 11:35'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 12:28'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 13:25'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 15:31'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 16:30'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 17:37'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 17:37'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 18:03'], ['REGENCY CAKESTAND 3 TIER', '12/8/2011 19:55'], ['WHITE HANGING HEART T-LIGHT HOLDER', '12/8/2011 19:55'], ['REGENCY CAKESTAND 3 TIER', '12/9/2011 10:20'], ['REGENCY CAKESTAND 3 TIER', '12/9/2011 10:23']]
--------------------
